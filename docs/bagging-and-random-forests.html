<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Topic 13 Bagging and Random Forests | STAT 253: Statistical Machine Learning</title>
  <meta name="description" content="This is the class website for Statistical Machine Learning at Macalester College." />
  <meta name="generator" content="bookdown 0.32 and GitBook 2.6.7" />

  <meta property="og:title" content="Topic 13 Bagging and Random Forests | STAT 253: Statistical Machine Learning" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is the class website for Statistical Machine Learning at Macalester College." />
  <meta name="github-repo" content="JamesNormington/253_spring_2023" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Topic 13 Bagging and Random Forests | STAT 253: Statistical Machine Learning" />
  
  <meta name="twitter:description" content="This is the class website for Statistical Machine Learning at Macalester College." />
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="decision-trees.html"/>
<link rel="next" href="homework-1.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="custom_styles.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href = "./">STAT 253: Statistical Machine Learning</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome!</a></li>
<li class="chapter" data-level="" data-path="schedule-syllabus.html"><a href="schedule-syllabus.html"><i class="fa fa-check"></i>Schedule &amp; Syllabus</a></li>
<li class="chapter" data-level="" data-path="learning-objectives.html"><a href="learning-objectives.html"><i class="fa fa-check"></i>Learning Objectives</a></li>
<li class="chapter" data-level="" data-path="r-and-rstudio-setup.html"><a href="r-and-rstudio-setup.html"><i class="fa fa-check"></i>R and RStudio Setup</a>
<ul>
<li class="chapter" data-level="" data-path="r-and-rstudio-setup.html"><a href="r-and-rstudio-setup.html#troubleshooting"><i class="fa fa-check"></i>Troubleshooting</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introductions.html"><a href="introductions.html"><i class="fa fa-check"></i><b>1</b> Introductions</a>
<ul>
<li class="chapter" data-level="" data-path="introductions.html"><a href="introductions.html#envisioning-a-community-of-learners"><i class="fa fa-check"></i>Envisioning a Community of Learners</a></li>
<li class="chapter" data-level="" data-path="introductions.html"><a href="introductions.html#explorations"><i class="fa fa-check"></i>Explorations</a></li>
</ul></li>
<li class="part"><span><b>I Regression: Evaluation</b></span></li>
<li class="chapter" data-level="2" data-path="evaluating-regression-models.html"><a href="evaluating-regression-models.html"><i class="fa fa-check"></i><b>2</b> Evaluating Regression Models</a>
<ul>
<li class="chapter" data-level="" data-path="evaluating-regression-models.html"><a href="evaluating-regression-models.html#learning-goals"><i class="fa fa-check"></i>Learning Goals</a></li>
<li class="chapter" data-level="" data-path="evaluating-regression-models.html"><a href="evaluating-regression-models.html#exercises"><i class="fa fa-check"></i>Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="evaluating-regression-models.html"><a href="evaluating-regression-models.html#context"><i class="fa fa-check"></i>Context</a></li>
<li class="chapter" data-level="" data-path="evaluating-regression-models.html"><a href="evaluating-regression-models.html#class-investigations"><i class="fa fa-check"></i>Class investigations</a></li>
<li class="chapter" data-level="" data-path="evaluating-regression-models.html"><a href="evaluating-regression-models.html#exercise-1"><i class="fa fa-check"></i>Exercise 1</a></li>
<li class="chapter" data-level="" data-path="evaluating-regression-models.html"><a href="evaluating-regression-models.html#exercise-2"><i class="fa fa-check"></i>Exercise 2</a></li>
<li class="chapter" data-level="" data-path="evaluating-regression-models.html"><a href="evaluating-regression-models.html#exercise-3"><i class="fa fa-check"></i>Exercise 3</a></li>
<li class="chapter" data-level="" data-path="evaluating-regression-models.html"><a href="evaluating-regression-models.html#exercise-4"><i class="fa fa-check"></i>Exercise 4</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="overfitting.html"><a href="overfitting.html"><i class="fa fa-check"></i><b>3</b> Overfitting</a>
<ul>
<li class="chapter" data-level="" data-path="overfitting.html"><a href="overfitting.html#learning-goals-1"><i class="fa fa-check"></i>Learning Goals</a></li>
<li class="chapter" data-level="" data-path="overfitting.html"><a href="overfitting.html#the-tidymodels-package"><i class="fa fa-check"></i>The <code>tidymodels</code> package</a></li>
<li class="chapter" data-level="" data-path="overfitting.html"><a href="overfitting.html#exercises-1"><i class="fa fa-check"></i>Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="overfitting.html"><a href="overfitting.html#context-1"><i class="fa fa-check"></i>Context</a></li>
<li class="chapter" data-level="" data-path="overfitting.html"><a href="overfitting.html#exercise-1-5-models"><i class="fa fa-check"></i>Exercise 1: 5 models</a></li>
<li class="chapter" data-level="" data-path="overfitting.html"><a href="overfitting.html#exercise-2-evaluating-the-test-data"><i class="fa fa-check"></i>Exercise 2: Evaluating the Test Data</a></li>
<li class="chapter" data-level="" data-path="overfitting.html"><a href="overfitting.html#exercise-3-overfitting"><i class="fa fa-check"></i>Exercise 3: Overfitting</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="cross-validation.html"><a href="cross-validation.html"><i class="fa fa-check"></i><b>4</b> Cross-validation</a>
<ul>
<li class="chapter" data-level="" data-path="cross-validation.html"><a href="cross-validation.html#learning-goals-2"><i class="fa fa-check"></i>Learning Goals</a></li>
<li class="chapter" data-level="" data-path="cross-validation.html"><a href="cross-validation.html#exercises-2"><i class="fa fa-check"></i>Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="cross-validation.html"><a href="cross-validation.html#context-2"><i class="fa fa-check"></i>Context</a></li>
<li class="chapter" data-level="" data-path="cross-validation.html"><a href="cross-validation.html#exercise-1-cross-validation-in-concept"><i class="fa fa-check"></i>Exercise 1: Cross-validation in Concept</a></li>
<li class="chapter" data-level="" data-path="cross-validation.html"><a href="cross-validation.html#exercise-2-cross-validation-with-tidymodels"><i class="fa fa-check"></i>Exercise 2: Cross-validation with <code>tidymodels</code></a></li>
<li class="chapter" data-level="" data-path="cross-validation.html"><a href="cross-validation.html#exercise-3-looking-at-the-evaluation-metrics"><i class="fa fa-check"></i>Exercise 3: Looking at the evaluation metrics</a></li>
<li class="chapter" data-level="" data-path="cross-validation.html"><a href="cross-validation.html#exercise-4-practical-issues-choosing-k"><i class="fa fa-check"></i>Exercise 4: Practical issues: choosing <span class="math inline">\(k\)</span></a></li>
<li class="chapter" data-level="" data-path="cross-validation.html"><a href="cross-validation.html#digging-deeper"><i class="fa fa-check"></i>Digging deeper</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Regression: Building Models</b></span></li>
<li class="chapter" data-level="5" data-path="variable-subset-selection.html"><a href="variable-subset-selection.html"><i class="fa fa-check"></i><b>5</b> Variable Subset Selection</a>
<ul>
<li class="chapter" data-level="" data-path="variable-subset-selection.html"><a href="variable-subset-selection.html#learning-goals-3"><i class="fa fa-check"></i>Learning Goals</a></li>
<li class="chapter" data-level="" data-path="variable-subset-selection.html"><a href="variable-subset-selection.html#exercises-3"><i class="fa fa-check"></i>Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="variable-subset-selection.html"><a href="variable-subset-selection.html#exercise-1-backward-stepwise-selection-by-hand"><i class="fa fa-check"></i>Exercise 1: Backward stepwise selection: by hand</a></li>
<li class="chapter" data-level="" data-path="variable-subset-selection.html"><a href="variable-subset-selection.html#exercise-2-interpreting-the-results"><i class="fa fa-check"></i>Exercise 2: Interpreting the results</a></li>
<li class="chapter" data-level="" data-path="variable-subset-selection.html"><a href="variable-subset-selection.html#exercise-3-planning-forward-selection-using-cv"><i class="fa fa-check"></i>Exercise 3: Planning forward selection using CV</a></li>
<li class="chapter" data-level="" data-path="variable-subset-selection.html"><a href="variable-subset-selection.html#exercise-4-stepwise-selection-in-caret"><i class="fa fa-check"></i>Exercise 4: Stepwise selection in <code>caret</code></a></li>
<li class="chapter" data-level="" data-path="variable-subset-selection.html"><a href="variable-subset-selection.html#exercise-5-exploring-the-results"><i class="fa fa-check"></i>Exercise 5: Exploring the results</a></li>
<li class="chapter" data-level="" data-path="variable-subset-selection.html"><a href="variable-subset-selection.html#digging-deeper-1"><i class="fa fa-check"></i>Digging deeper</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="lasso-shrinkageregularization.html"><a href="lasso-shrinkageregularization.html"><i class="fa fa-check"></i><b>6</b> LASSO: Shrinkage/Regularization</a>
<ul>
<li class="chapter" data-level="" data-path="lasso-shrinkageregularization.html"><a href="lasso-shrinkageregularization.html#learning-goals-4"><i class="fa fa-check"></i>Learning Goals</a></li>
<li class="chapter" data-level="" data-path="lasso-shrinkageregularization.html"><a href="lasso-shrinkageregularization.html#lasso-models-in-tidymodels"><i class="fa fa-check"></i>LASSO models in <code>tidymodels</code></a></li>
<li class="chapter" data-level="" data-path="lasso-shrinkageregularization.html"><a href="lasso-shrinkageregularization.html#exercises-4"><i class="fa fa-check"></i>Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="lasso-shrinkageregularization.html"><a href="lasso-shrinkageregularization.html#exercise-1-a-least-squares-model"><i class="fa fa-check"></i>Exercise 1: A least squares model</a></li>
<li class="chapter" data-level="" data-path="lasso-shrinkageregularization.html"><a href="lasso-shrinkageregularization.html#exercise-2-fitting-a-lasso-model-in-tidymodels"><i class="fa fa-check"></i>Exercise 2: Fitting a LASSO model in <code>tidymodels</code></a></li>
<li class="chapter" data-level="" data-path="lasso-shrinkageregularization.html"><a href="lasso-shrinkageregularization.html#exercise-3-examining-output-plot-of-coefficient-paths"><i class="fa fa-check"></i>Exercise 3: Examining output: plot of coefficient paths</a></li>
<li class="chapter" data-level="" data-path="lasso-shrinkageregularization.html"><a href="lasso-shrinkageregularization.html#exercise-4-examining-and-evaluating-the-best-lasso-model."><i class="fa fa-check"></i>Exercise 4: Examining and evaluating the best LASSO model.</a></li>
<li class="chapter" data-level="" data-path="lasso-shrinkageregularization.html"><a href="lasso-shrinkageregularization.html#digging-deeper-2"><i class="fa fa-check"></i>Digging deeper</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Regression: Building Flexible Models</b></span></li>
<li class="chapter" data-level="7" data-path="knn-regression-and-the-bias-variance-tradeoff.html"><a href="knn-regression-and-the-bias-variance-tradeoff.html"><i class="fa fa-check"></i><b>7</b> KNN Regression and the Bias-Variance Tradeoff</a>
<ul>
<li class="chapter" data-level="" data-path="knn-regression-and-the-bias-variance-tradeoff.html"><a href="knn-regression-and-the-bias-variance-tradeoff.html#learning-goals-5"><i class="fa fa-check"></i>Learning Goals</a></li>
<li class="chapter" data-level="" data-path="knn-regression-and-the-bias-variance-tradeoff.html"><a href="knn-regression-and-the-bias-variance-tradeoff.html#knn-models-in-tidymodels"><i class="fa fa-check"></i>KNN models in <code>tidymodels</code></a></li>
<li class="chapter" data-level="" data-path="knn-regression-and-the-bias-variance-tradeoff.html"><a href="knn-regression-and-the-bias-variance-tradeoff.html#exercises-5"><i class="fa fa-check"></i>Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="knn-regression-and-the-bias-variance-tradeoff.html"><a href="knn-regression-and-the-bias-variance-tradeoff.html#exercise-1-bias-variance-tradeoff-warmup"><i class="fa fa-check"></i>Exercise 1: Bias-variance tradeoff warmup</a></li>
<li class="chapter" data-level="" data-path="knn-regression-and-the-bias-variance-tradeoff.html"><a href="knn-regression-and-the-bias-variance-tradeoff.html#exercise-2-impact-of-distance-metric"><i class="fa fa-check"></i>Exercise 2: Impact of distance metric</a></li>
<li class="chapter" data-level="" data-path="knn-regression-and-the-bias-variance-tradeoff.html"><a href="knn-regression-and-the-bias-variance-tradeoff.html#exercise-3-implementing-knn-in-tidymodels"><i class="fa fa-check"></i>Exercise 3: Implementing KNN in <code>tidymodels</code></a></li>
<li class="chapter" data-level="" data-path="knn-regression-and-the-bias-variance-tradeoff.html"><a href="knn-regression-and-the-bias-variance-tradeoff.html#exercise-4-inspecting-the-results"><i class="fa fa-check"></i>Exercise 4: Inspecting the results</a></li>
<li class="chapter" data-level="" data-path="knn-regression-and-the-bias-variance-tradeoff.html"><a href="knn-regression-and-the-bias-variance-tradeoff.html#exercise-5-curse-of-dimensionality"><i class="fa fa-check"></i>Exercise 5: Curse of dimensionality</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="splines.html"><a href="splines.html"><i class="fa fa-check"></i><b>8</b> Splines</a>
<ul>
<li class="chapter" data-level="" data-path="splines.html"><a href="splines.html#learning-goals-6"><i class="fa fa-check"></i>Learning Goals</a></li>
<li class="chapter" data-level="" data-path="splines.html"><a href="splines.html#splines-in-tidymodels"><i class="fa fa-check"></i>Splines in <code>tidymodels</code></a></li>
<li class="chapter" data-level="" data-path="splines.html"><a href="splines.html#exercises-6"><i class="fa fa-check"></i>Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="splines.html"><a href="splines.html#exercise-1-evaluating-a-fully-linear-model"><i class="fa fa-check"></i>Exercise 1: Evaluating a fully linear model</a></li>
<li class="chapter" data-level="" data-path="splines.html"><a href="splines.html#exercise-2-evaluating-a-spline-model"><i class="fa fa-check"></i>Exercise 2: Evaluating a spline model</a></li>
<li class="chapter" data-level="" data-path="splines.html"><a href="splines.html#extra-variable-scaling"><i class="fa fa-check"></i>Extra! Variable scaling</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="local-regression-gams.html"><a href="local-regression-gams.html"><i class="fa fa-check"></i><b>9</b> Local Regression &amp; GAMs</a>
<ul>
<li class="chapter" data-level="" data-path="local-regression-gams.html"><a href="local-regression-gams.html#learning-goals-7"><i class="fa fa-check"></i>Learning Goals</a></li>
<li class="chapter" data-level="9.1" data-path="local-regression-gams.html"><a href="local-regression-gams.html#gams"><i class="fa fa-check"></i><b>9.1</b> GAMs</a></li>
<li class="chapter" data-level="9.2" data-path="local-regression-gams.html"><a href="local-regression-gams.html#gams---options-for-fitting"><i class="fa fa-check"></i><b>9.2</b> GAMs - Options for Fitting</a></li>
<li class="chapter" data-level="" data-path="local-regression-gams.html"><a href="local-regression-gams.html#gams-in-tidymodels"><i class="fa fa-check"></i>GAMs in <code>tidymodels</code></a></li>
<li class="chapter" data-level="" data-path="local-regression-gams.html"><a href="local-regression-gams.html#exercises-7"><i class="fa fa-check"></i>Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="local-regression-gams.html"><a href="local-regression-gams.html#exercise-1-conceptual-warmup"><i class="fa fa-check"></i>Exercise 1: Conceptual warmup</a></li>
<li class="chapter" data-level="" data-path="local-regression-gams.html"><a href="local-regression-gams.html#exercise-2-using-loess"><i class="fa fa-check"></i>Exercise 2: Using LOESS</a></li>
<li class="chapter" data-level="" data-path="local-regression-gams.html"><a href="local-regression-gams.html#exercise-3-building-a-gam-in-tidymodels"><i class="fa fa-check"></i>Exercise 3: Building a GAM in <code>tidymodels</code></a></li>
<li class="chapter" data-level="" data-path="local-regression-gams.html"><a href="local-regression-gams.html#exercise-4-adjusting-the-best-gam"><i class="fa fa-check"></i>Exercise 4: Adjusting the “best” GAM</a></li>
<li class="chapter" data-level="" data-path="local-regression-gams.html"><a href="local-regression-gams.html#exercise-5-gam-with-recipes"><i class="fa fa-check"></i>Exercise 5: GAM with recipes</a></li>
<li class="chapter" data-level="" data-path="local-regression-gams.html"><a href="local-regression-gams.html#exercise-6-putting-a-bow-on-regression"><i class="fa fa-check"></i>Exercise 6: putting a bow on regression</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IV Classification</b></span></li>
<li class="chapter" data-level="10" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>10</b> Logistic Regression</a>
<ul>
<li class="chapter" data-level="" data-path="logistic-regression.html"><a href="logistic-regression.html#learning-goals-8"><i class="fa fa-check"></i>Learning Goals</a></li>
<li class="chapter" data-level="" data-path="logistic-regression.html"><a href="logistic-regression.html#logistic-regression-in-tidymodels"><i class="fa fa-check"></i>Logistic regression in <code>tidymodels</code></a></li>
<li class="chapter" data-level="" data-path="logistic-regression.html"><a href="logistic-regression.html#exercises-8"><i class="fa fa-check"></i>Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="logistic-regression.html"><a href="logistic-regression.html#context-and-data"><i class="fa fa-check"></i>Context and Data</a></li>
<li class="chapter" data-level="" data-path="logistic-regression.html"><a href="logistic-regression.html#exercise-1-visualization-warmup"><i class="fa fa-check"></i>Exercise 1: Visualization warmup</a></li>
<li class="chapter" data-level="" data-path="logistic-regression.html"><a href="logistic-regression.html#exercise-2-implementing-logistic-regression-in-tidymodels"><i class="fa fa-check"></i>Exercise 2: Implementing logistic regression in <code>tidymodels</code></a></li>
<li class="chapter" data-level="" data-path="logistic-regression.html"><a href="logistic-regression.html#exercise-3-interpreting-the-model"><i class="fa fa-check"></i>Exercise 3: Interpreting the model</a></li>
<li class="chapter" data-level="" data-path="logistic-regression.html"><a href="logistic-regression.html#exercise-4-making-predictions"><i class="fa fa-check"></i>Exercise 4: Making predictions</a></li>
<li class="chapter" data-level="10.0.1" data-path="logistic-regression.html"><a href="logistic-regression.html#exercise-5-evaluate-the-model"><i class="fa fa-check"></i><b>10.0.1</b> Exercise 5: Evaluate the model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="lasso-logistic-regression.html"><a href="lasso-logistic-regression.html"><i class="fa fa-check"></i><b>11</b> Lasso &amp; Logistic Regression</a>
<ul>
<li class="chapter" data-level="" data-path="lasso-logistic-regression.html"><a href="lasso-logistic-regression.html#learning-goals-9"><i class="fa fa-check"></i>Learning Goals</a></li>
<li class="chapter" data-level="" data-path="lasso-logistic-regression.html"><a href="lasso-logistic-regression.html#lasso-for-logistic-regression-in-tidymodels"><i class="fa fa-check"></i>LASSO for logistic regression in <code>tidymodels</code></a></li>
<li class="chapter" data-level="" data-path="lasso-logistic-regression.html"><a href="lasso-logistic-regression.html#exercises-9"><i class="fa fa-check"></i>Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="lasso-logistic-regression.html"><a href="lasso-logistic-regression.html#context-3"><i class="fa fa-check"></i>Context</a></li>
<li class="chapter" data-level="" data-path="lasso-logistic-regression.html"><a href="lasso-logistic-regression.html#exercise-1-conceptual-warmup-1"><i class="fa fa-check"></i>Exercise 1: Conceptual warmup</a></li>
<li class="chapter" data-level="" data-path="lasso-logistic-regression.html"><a href="lasso-logistic-regression.html#exercise-2-implementing-lasso-logistic-regression-in-tidymodels"><i class="fa fa-check"></i>Exercise 2: Implementing LASSO logistic regression in <code>tidymodels</code></a></li>
<li class="chapter" data-level="" data-path="lasso-logistic-regression.html"><a href="lasso-logistic-regression.html#exercise-3-inspecting-the-model"><i class="fa fa-check"></i>Exercise 3: Inspecting the model</a></li>
<li class="chapter" data-level="" data-path="lasso-logistic-regression.html"><a href="lasso-logistic-regression.html#exercise-4-interpreting-evaluation-metrics"><i class="fa fa-check"></i>Exercise 4: Interpreting evaluation metrics</a></li>
<li class="chapter" data-level="" data-path="lasso-logistic-regression.html"><a href="lasso-logistic-regression.html#exercise-5-using-the-final-model-choosing-a-threshold"><i class="fa fa-check"></i>Exercise 5: Using the final model (choosing a threshold)</a></li>
<li class="chapter" data-level="" data-path="lasso-logistic-regression.html"><a href="lasso-logistic-regression.html#exercise-6-algorithmic-understanding-for-evaluation-metrics"><i class="fa fa-check"></i>Exercise 6: Algorithmic understanding for evaluation metrics</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="decision-trees.html"><a href="decision-trees.html"><i class="fa fa-check"></i><b>12</b> Decision Trees</a>
<ul>
<li class="chapter" data-level="" data-path="decision-trees.html"><a href="decision-trees.html#learning-goals-10"><i class="fa fa-check"></i>Learning Goals</a></li>
<li class="chapter" data-level="" data-path="decision-trees.html"><a href="decision-trees.html#trees-in-tidymodels"><i class="fa fa-check"></i>Trees in <code>tidymodels</code></a></li>
<li class="chapter" data-level="" data-path="decision-trees.html"><a href="decision-trees.html#exercises-part-1"><i class="fa fa-check"></i>Exercises Part 1</a>
<ul>
<li class="chapter" data-level="" data-path="decision-trees.html"><a href="decision-trees.html#context-4"><i class="fa fa-check"></i>Context</a></li>
<li class="chapter" data-level="" data-path="decision-trees.html"><a href="decision-trees.html#exercise-1-core-theme-parametricnonparametric"><i class="fa fa-check"></i>Exercise 1: Core theme: parametric/nonparametric</a></li>
<li class="chapter" data-level="" data-path="decision-trees.html"><a href="decision-trees.html#exercise-2-core-theme-tuning-parameters-and-the-bvt"><i class="fa fa-check"></i>Exercise 2: Core theme: Tuning parameters and the BVT</a></li>
<li class="chapter" data-level="" data-path="decision-trees.html"><a href="decision-trees.html#exercise-3-building-trees-in-tidymodels"><i class="fa fa-check"></i>Exercise 3: Building trees in <code>tidymodels</code></a></li>
<li class="chapter" data-level="" data-path="decision-trees.html"><a href="decision-trees.html#exercise-4-visualizing-trees"><i class="fa fa-check"></i>Exercise 4: Visualizing trees</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="decision-trees.html"><a href="decision-trees.html#exercises-part-2"><i class="fa fa-check"></i>Exercises Part 2</a>
<ul>
<li class="chapter" data-level="" data-path="decision-trees.html"><a href="decision-trees.html#exercise-5-predictions-from-trees"><i class="fa fa-check"></i>Exercise 5: Predictions from Trees</a></li>
<li class="chapter" data-level="" data-path="decision-trees.html"><a href="decision-trees.html#exercise-6-variable-importance-in-trees"><i class="fa fa-check"></i>Exercise 6: Variable importance in trees</a></li>
<li class="chapter" data-level="" data-path="decision-trees.html"><a href="decision-trees.html#exercise-7-regression-trees"><i class="fa fa-check"></i>Exercise 7: REGRESSION trees?!</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="bagging-and-random-forests.html"><a href="bagging-and-random-forests.html"><i class="fa fa-check"></i><b>13</b> Bagging and Random Forests</a>
<ul>
<li class="chapter" data-level="" data-path="bagging-and-random-forests.html"><a href="bagging-and-random-forests.html#learning-goals-11"><i class="fa fa-check"></i>Learning Goals</a></li>
<li class="chapter" data-level="" data-path="bagging-and-random-forests.html"><a href="bagging-and-random-forests.html#exercises-10"><i class="fa fa-check"></i>Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="bagging-and-random-forests.html"><a href="bagging-and-random-forests.html#exercise-1-bagging-bootstrap-aggregation"><i class="fa fa-check"></i>Exercise 1: Bagging: <em>B</em>ootstrap <em>AGG</em>regation</a></li>
<li class="chapter" data-level="" data-path="bagging-and-random-forests.html"><a href="bagging-and-random-forests.html#exercise-2-random-forest-groundwork"><i class="fa fa-check"></i>Exercise 2: Random forest groundwork</a></li>
<li class="chapter" data-level="" data-path="bagging-and-random-forests.html"><a href="bagging-and-random-forests.html#exercise-3-building-the-random-forest"><i class="fa fa-check"></i>Exercise 3: Building the random forest</a></li>
<li class="chapter" data-level="" data-path="bagging-and-random-forests.html"><a href="bagging-and-random-forests.html#exercise-4-preliminary-interpretation"><i class="fa fa-check"></i>Exercise 4: Preliminary interpretation</a></li>
<li class="chapter" data-level="" data-path="bagging-and-random-forests.html"><a href="bagging-and-random-forests.html#exercise-5-evaluating-the-forest"><i class="fa fa-check"></i>Exercise 5: Evaluating the forest</a></li>
<li class="chapter" data-level="" data-path="bagging-and-random-forests.html"><a href="bagging-and-random-forests.html#exercise-6-variable-importance-measures"><i class="fa fa-check"></i>Exercise 6: Variable importance measures</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>V Homework</b></span></li>
<li class="chapter" data-level="" data-path="homework-1.html"><a href="homework-1.html"><i class="fa fa-check"></i>Homework 1</a>
<ul>
<li class="chapter" data-level="" data-path="homework-1.html"><a href="homework-1.html#project-work"><i class="fa fa-check"></i>Project Work</a></li>
<li class="chapter" data-level="" data-path="homework-1.html"><a href="homework-1.html#ethics-in-ml"><i class="fa fa-check"></i>Ethics in ML</a></li>
<li class="chapter" data-level="" data-path="homework-1.html"><a href="homework-1.html#portfolio-work"><i class="fa fa-check"></i>Portfolio Work</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="homework-2.html"><a href="homework-2.html"><i class="fa fa-check"></i>Homework 2</a>
<ul>
<li class="chapter" data-level="" data-path="homework-2.html"><a href="homework-2.html#project-work-1"><i class="fa fa-check"></i>Project Work</a></li>
<li class="chapter" data-level="" data-path="homework-2.html"><a href="homework-2.html#ethics-in-ml-1"><i class="fa fa-check"></i>Ethics in ML</a></li>
<li class="chapter" data-level="" data-path="homework-2.html"><a href="homework-2.html#portfolio-work-1"><i class="fa fa-check"></i>Portfolio Work</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="homework-3.html"><a href="homework-3.html"><i class="fa fa-check"></i>Homework 3</a>
<ul>
<li class="chapter" data-level="" data-path="homework-3.html"><a href="homework-3.html#project-work-2"><i class="fa fa-check"></i>Project Work</a>
<ul>
<li class="chapter" data-level="" data-path="homework-3.html"><a href="homework-3.html#note-this-is-a-repeat-of-hw2.-many-of-you-struggled-with-this-section-so-this-gives-you-an-opportunity-to-incorporate-feedback-from-the-preceptors-or-try-additional-models."><i class="fa fa-check"></i>Note: this is a repeat of HW2. Many of you struggled with this section, so this gives you an opportunity to incorporate feedback from the preceptors, or try additional models.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="homework-3.html"><a href="homework-3.html#portfolio-work-2"><i class="fa fa-check"></i>Portfolio Work</a></li>
<li class="chapter" data-level="" data-path="homework-3.html"><a href="homework-3.html#ethics-in-ml-2"><i class="fa fa-check"></i>Ethics in ML</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="r-resources.html"><a href="r-resources.html"><i class="fa fa-check"></i>R Resources</a>
<ul>
<li class="chapter" data-level="" data-path="r-resources.html"><a href="r-resources.html#outside-resources"><i class="fa fa-check"></i>Outside resources</a></li>
<li class="chapter" data-level="" data-path="r-resources.html"><a href="r-resources.html#example-code"><i class="fa fa-check"></i>Example code</a></li>
</ul></li>
<li class="part"><span><b>VI Project</b></span></li>
<li class="chapter" data-level="" data-path="final-project.html"><a href="final-project.html"><i class="fa fa-check"></i>Final Project</a>
<ul>
<li class="chapter" data-level="" data-path="final-project.html"><a href="final-project.html#requirements"><i class="fa fa-check"></i>Requirements</a></li>
<li class="chapter" data-level="" data-path="final-project.html"><a href="final-project.html#grading-rubric"><i class="fa fa-check"></i>Grading Rubric</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">STAT 253: Statistical Machine Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="bagging-and-random-forests" class="section level1 hasAnchor" number="13">
<h1><span class="header-section-number">Topic 13</span> Bagging and Random Forests<a href="bagging-and-random-forests.html#bagging-and-random-forests" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="learning-goals-11" class="section level2 unnumbered hasAnchor">
<h2>Learning Goals<a href="bagging-and-random-forests.html#learning-goals-11" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li>Explain the rationale for bagging</li>
<li>Explain the rationale for selecting a random subset of predictors at each split (random forests)</li>
<li>Explain how the size of the random subset of predictors at each split relates to the bias-variance tradeoff</li>
<li>Explain the rationale for and implement out-of-bag error estimation for both regression and classification</li>
<li>Explain the rationale behind the random forest variable importance measure and why it is biased towards quantitative predictors</li>
</ul>
<p><br><br><br></p>
</div>
<div id="exercises-10" class="section level2 unnumbered hasAnchor">
<h2>Exercises<a href="bagging-and-random-forests.html#exercises-10" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><strong>You can download a template RMarkdown file to start from <a href="template_rmds/13-bagging-rf.Rmd">here</a>.</strong></p>
<p>Before proceeding, install the <code>ranger</code> and <code>vip</code> packages.</p>
<p>Our goal will be to classify types of urban land cover in small subregions within a high resolution aerial image of a land region. Data from the <a href="https://archive.ics.uci.edu/ml/datasets/Urban+Land+Cover">UCI Machine Learning Repository</a> include the observed type of land cover (determined by human eye) and “spectral, size, shape, and texture information” computed from the image. See <a href="https://archive.ics.uci.edu/ml/datasets/Urban+Land+Cover">this page</a> for the data codebook.</p>
<center>
<img src="https://ncap.org.uk/sites/default/files/EK_land_use_0.jpg"><br>
Source: <a href="https://ncap.org.uk/sites/default/files/EK_land_use_0.jpg" class="uri">https://ncap.org.uk/sites/default/files/EK_land_use_0.jpg</a>
</center>
<div class="sourceCode" id="cb121"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb121-1"><a href="bagging-and-random-forests.html#cb121-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(readr)</span>
<span id="cb121-2"><a href="bagging-and-random-forests.html#cb121-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb121-3"><a href="bagging-and-random-forests.html#cb121-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb121-4"><a href="bagging-and-random-forests.html#cb121-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb121-5"><a href="bagging-and-random-forests.html#cb121-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart.plot)</span>
<span id="cb121-6"><a href="bagging-and-random-forests.html#cb121-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(randomForest)</span>
<span id="cb121-7"><a href="bagging-and-random-forests.html#cb121-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb121-8"><a href="bagging-and-random-forests.html#cb121-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Read in the data</span></span>
<span id="cb121-9"><a href="bagging-and-random-forests.html#cb121-9" aria-hidden="true" tabindex="-1"></a>land <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">&quot;https://ajohns24.github.io/portfolio/data/land_cover.csv&quot;</span>)</span>
<span id="cb121-10"><a href="bagging-and-random-forests.html#cb121-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb121-11"><a href="bagging-and-random-forests.html#cb121-11" aria-hidden="true" tabindex="-1"></a><span class="co"># There are 9 land types, but we&#39;ll focus on 3 of them</span></span>
<span id="cb121-12"><a href="bagging-and-random-forests.html#cb121-12" aria-hidden="true" tabindex="-1"></a>land <span class="ot">&lt;-</span> land <span class="sc">%&gt;%</span> </span>
<span id="cb121-13"><a href="bagging-and-random-forests.html#cb121-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">filter</span>(class <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">&quot;asphalt&quot;</span>, <span class="st">&quot;grass&quot;</span>, <span class="st">&quot;tree&quot;</span>))</span></code></pre></div>
<div id="exercise-1-bagging-bootstrap-aggregation" class="section level3 unnumbered hasAnchor">
<h3>Exercise 1: Bagging: <em>B</em>ootstrap <em>AGG</em>regation<a href="bagging-and-random-forests.html#exercise-1-bagging-bootstrap-aggregation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ol style="list-style-type: lower-alpha">
<li><p>First, explain to your table mates what bootstrapping is (the algorithm).</p></li>
<li><p>Discuss why we might utilize bootstrapping? What do we gain? Why did we use bootstrapping in STAT 155?</p></li>
</ol>
<p>Note: In practice, we don’t often use bagged trees as the final classifier because the trees end up looking too similar to each other so we create random forests (bagged trees + use random subset of variables to choose split from).</p>
</div>
<div id="exercise-2-random-forest-groundwork" class="section level3 unnumbered hasAnchor">
<h3>Exercise 2: Random forest groundwork<a href="bagging-and-random-forests.html#exercise-2-random-forest-groundwork" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Suppose we wanted to evaluate the performance of a random forest which uses 500 classification trees.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Describe the 10-fold CV approach to evaluating the random forest. In this process, how many total trees would we need to construct?</p></li>
<li><p>The <strong>out-of-bag (OOB) error rate</strong> provides an alternative approach to evaluating forests. Unlike CV, OOB summarizes misclassification rates when applying each of the 500 trees to the “test” cases that were not used to build the tree. How many total trees would we need to construct in order to calculate the OOB error estimate?</p></li>
<li><p>Moving forward, we’ll use OOB and not CV to evaluate forest performance. Explain why.</p></li>
</ol>
</div>
<div id="exercise-3-building-the-random-forest" class="section level3 unnumbered hasAnchor">
<h3>Exercise 3: Building the random forest<a href="bagging-and-random-forests.html#exercise-3-building-the-random-forest" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We can now put together our work to train our random forest model. Build a set of random forest models with the following specifications:</p>
<ul>
<li>Set the seed to 253.</li>
<li>Run the algorithm with the following number of randomly sampled predictors at each split: 2, 12 (roughly <span class="math inline">\(\sqrt{147}\)</span>), 74 (roughly 147/2), and all 147 predictors</li>
<li>You can generate a sequence of numbers with <code>c()</code>. e.g., <code>c(2,3)</code>.</li>
<li>Use OOB instead of CV for model evaluation.</li>
<li>Select the model with the overall best value of estimated test overall accuracy.</li>
</ul>
<div class="sourceCode" id="cb122"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb122-1"><a href="bagging-and-random-forests.html#cb122-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make sure you understand what each line of code is doing</span></span>
<span id="cb122-2"><a href="bagging-and-random-forests.html#cb122-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb122-3"><a href="bagging-and-random-forests.html#cb122-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Model Specification</span></span>
<span id="cb122-4"><a href="bagging-and-random-forests.html#cb122-4" aria-hidden="true" tabindex="-1"></a>rf_spec <span class="ot">&lt;-</span> <span class="fu">rand_forest</span>() <span class="sc">%&gt;%</span></span>
<span id="cb122-5"><a href="bagging-and-random-forests.html#cb122-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="at">engine =</span> <span class="st">&#39;ranger&#39;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb122-6"><a href="bagging-and-random-forests.html#cb122-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_args</span>(<span class="at">mtry =</span> <span class="cn">NULL</span>, <span class="co"># size of random subset of variables; default is floor(sqrt(number of total predictors))</span></span>
<span id="cb122-7"><a href="bagging-and-random-forests.html#cb122-7" aria-hidden="true" tabindex="-1"></a>           <span class="at">trees =</span> <span class="dv">1000</span>, <span class="co"># Number of trees</span></span>
<span id="cb122-8"><a href="bagging-and-random-forests.html#cb122-8" aria-hidden="true" tabindex="-1"></a>           <span class="at">min_n =</span> <span class="dv">2</span>,</span>
<span id="cb122-9"><a href="bagging-and-random-forests.html#cb122-9" aria-hidden="true" tabindex="-1"></a>           <span class="at">probability =</span> <span class="cn">FALSE</span>, <span class="co"># FALSE: get hard predictions (not needed for regression)</span></span>
<span id="cb122-10"><a href="bagging-and-random-forests.html#cb122-10" aria-hidden="true" tabindex="-1"></a>           <span class="at">importance =</span> <span class="st">&#39;impurity&#39;</span>) <span class="sc">%&gt;%</span> <span class="co"># we&#39;ll come back to this at the end</span></span>
<span id="cb122-11"><a href="bagging-and-random-forests.html#cb122-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&#39;classification&#39;</span>) <span class="co"># change this for regression</span></span>
<span id="cb122-12"><a href="bagging-and-random-forests.html#cb122-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb122-13"><a href="bagging-and-random-forests.html#cb122-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Recipe</span></span>
<span id="cb122-14"><a href="bagging-and-random-forests.html#cb122-14" aria-hidden="true" tabindex="-1"></a>data_rec <span class="ot">&lt;-</span> <span class="fu">recipe</span>(class <span class="sc">~</span> ., <span class="at">data =</span> land)</span>
<span id="cb122-15"><a href="bagging-and-random-forests.html#cb122-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb122-16"><a href="bagging-and-random-forests.html#cb122-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Workflows</span></span>
<span id="cb122-17"><a href="bagging-and-random-forests.html#cb122-17" aria-hidden="true" tabindex="-1"></a>data_wf_mtry2 <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">%&gt;%</span></span>
<span id="cb122-18"><a href="bagging-and-random-forests.html#cb122-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_model</span>(rf_spec <span class="sc">%&gt;%</span> <span class="fu">set_args</span>(<span class="at">mtry =</span> <span class="dv">2</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb122-19"><a href="bagging-and-random-forests.html#cb122-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_recipe</span>(data_rec)</span>
<span id="cb122-20"><a href="bagging-and-random-forests.html#cb122-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb122-21"><a href="bagging-and-random-forests.html#cb122-21" aria-hidden="true" tabindex="-1"></a><span class="do">## Create workflows for mtry = 12, 74, and 147</span></span>
<span id="cb122-22"><a href="bagging-and-random-forests.html#cb122-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb122-23"><a href="bagging-and-random-forests.html#cb122-23" aria-hidden="true" tabindex="-1"></a>data_wf_mtry12 <span class="ot">&lt;-</span> </span>
<span id="cb122-24"><a href="bagging-and-random-forests.html#cb122-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb122-25"><a href="bagging-and-random-forests.html#cb122-25" aria-hidden="true" tabindex="-1"></a>data_wf_mtry74 <span class="ot">&lt;-</span> </span>
<span id="cb122-26"><a href="bagging-and-random-forests.html#cb122-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb122-27"><a href="bagging-and-random-forests.html#cb122-27" aria-hidden="true" tabindex="-1"></a>data_wf_mtry147 <span class="ot">&lt;-</span> </span></code></pre></div>
<div class="sourceCode" id="cb123"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb123-1"><a href="bagging-and-random-forests.html#cb123-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit Models</span></span>
<span id="cb123-2"><a href="bagging-and-random-forests.html#cb123-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>) <span class="co"># make sure to run this before each fit so that you have the same 1000 trees</span></span>
<span id="cb123-3"><a href="bagging-and-random-forests.html#cb123-3" aria-hidden="true" tabindex="-1"></a>data_fit_mtry2 <span class="ot">&lt;-</span> <span class="fu">fit</span>(data_wf_mtry2, <span class="at">data =</span> land)</span>
<span id="cb123-4"><a href="bagging-and-random-forests.html#cb123-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb123-5"><a href="bagging-and-random-forests.html#cb123-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit models for 12, 74, 147</span></span>
<span id="cb123-6"><a href="bagging-and-random-forests.html#cb123-6" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>) </span>
<span id="cb123-7"><a href="bagging-and-random-forests.html#cb123-7" aria-hidden="true" tabindex="-1"></a>data_fit_mtry12 <span class="ot">&lt;-</span> </span>
<span id="cb123-8"><a href="bagging-and-random-forests.html#cb123-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb123-9"><a href="bagging-and-random-forests.html#cb123-9" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb123-10"><a href="bagging-and-random-forests.html#cb123-10" aria-hidden="true" tabindex="-1"></a>data_fit_mtry74 <span class="ot">&lt;-</span> </span>
<span id="cb123-11"><a href="bagging-and-random-forests.html#cb123-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb123-12"><a href="bagging-and-random-forests.html#cb123-12" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>) </span>
<span id="cb123-13"><a href="bagging-and-random-forests.html#cb123-13" aria-hidden="true" tabindex="-1"></a>data_fit_mtry147 <span class="ot">&lt;-</span> </span></code></pre></div>
<div class="sourceCode" id="cb124"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb124-1"><a href="bagging-and-random-forests.html#cb124-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Custom Function to get OOB predictions, true observed outcomes and add a user-provided model label</span></span>
<span id="cb124-2"><a href="bagging-and-random-forests.html#cb124-2" aria-hidden="true" tabindex="-1"></a>rf_OOB_output <span class="ot">&lt;-</span> <span class="cf">function</span>(fit_model, model_label, truth){</span>
<span id="cb124-3"><a href="bagging-and-random-forests.html#cb124-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">tibble</span>(</span>
<span id="cb124-4"><a href="bagging-and-random-forests.html#cb124-4" aria-hidden="true" tabindex="-1"></a>          <span class="at">.pred_class =</span> fit_model <span class="sc">%&gt;%</span> <span class="fu">extract_fit_engine</span>() <span class="sc">%&gt;%</span> <span class="fu">pluck</span>(<span class="st">&#39;predictions&#39;</span>), <span class="co">#OOB predictions</span></span>
<span id="cb124-5"><a href="bagging-and-random-forests.html#cb124-5" aria-hidden="true" tabindex="-1"></a>          <span class="at">class =</span> truth,</span>
<span id="cb124-6"><a href="bagging-and-random-forests.html#cb124-6" aria-hidden="true" tabindex="-1"></a>          <span class="at">label =</span> model_label</span>
<span id="cb124-7"><a href="bagging-and-random-forests.html#cb124-7" aria-hidden="true" tabindex="-1"></a>      )</span>
<span id="cb124-8"><a href="bagging-and-random-forests.html#cb124-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb124-9"><a href="bagging-and-random-forests.html#cb124-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-10"><a href="bagging-and-random-forests.html#cb124-10" aria-hidden="true" tabindex="-1"></a><span class="co">#check out the function output</span></span>
<span id="cb124-11"><a href="bagging-and-random-forests.html#cb124-11" aria-hidden="true" tabindex="-1"></a><span class="fu">rf_OOB_output</span>(data_fit_mtry2,<span class="dv">2</span>, land <span class="sc">%&gt;%</span> <span class="fu">pull</span>(class))</span></code></pre></div>
<div class="sourceCode" id="cb125"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb125-1"><a href="bagging-and-random-forests.html#cb125-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate OOB Metrics</span></span>
<span id="cb125-2"><a href="bagging-and-random-forests.html#cb125-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb125-3"><a href="bagging-and-random-forests.html#cb125-3" aria-hidden="true" tabindex="-1"></a>data_rf_OOB_output <span class="ot">&lt;-</span> <span class="fu">bind_rows</span>(</span>
<span id="cb125-4"><a href="bagging-and-random-forests.html#cb125-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">rf_OOB_output</span>(data_fit_mtry2,<span class="dv">2</span>, land <span class="sc">%&gt;%</span> <span class="fu">pull</span>(class)),</span>
<span id="cb125-5"><a href="bagging-and-random-forests.html#cb125-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">rf_OOB_output</span>(data_fit_mtry12,<span class="dv">12</span>, land <span class="sc">%&gt;%</span> <span class="fu">pull</span>(class)),</span>
<span id="cb125-6"><a href="bagging-and-random-forests.html#cb125-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">rf_OOB_output</span>(data_fit_mtry74,<span class="dv">74</span>, land <span class="sc">%&gt;%</span> <span class="fu">pull</span>(class)),</span>
<span id="cb125-7"><a href="bagging-and-random-forests.html#cb125-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">rf_OOB_output</span>(data_fit_mtry147,<span class="dv">147</span>, land <span class="sc">%&gt;%</span> <span class="fu">pull</span>(class))</span>
<span id="cb125-8"><a href="bagging-and-random-forests.html#cb125-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb125-9"><a href="bagging-and-random-forests.html#cb125-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb125-10"><a href="bagging-and-random-forests.html#cb125-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb125-11"><a href="bagging-and-random-forests.html#cb125-11" aria-hidden="true" tabindex="-1"></a>data_rf_OOB_output <span class="sc">%&gt;%</span> </span>
<span id="cb125-12"><a href="bagging-and-random-forests.html#cb125-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">group_by</span>(label) <span class="sc">%&gt;%</span></span>
<span id="cb125-13"><a href="bagging-and-random-forests.html#cb125-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">accuracy</span>(<span class="at">truth =</span> class, <span class="at">estimate =</span> .pred_class)</span></code></pre></div>
</div>
<div id="exercise-4-preliminary-interpretation" class="section level3 unnumbered hasAnchor">
<h3>Exercise 4: Preliminary interpretation<a href="bagging-and-random-forests.html#exercise-4-preliminary-interpretation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ol style="list-style-type: lower-alpha">
<li><p>Plot estimated test performance vs. the tuning parameter, <code>mtry</code>. What tuning parameter would you choose?</p></li>
<li><p>Describe the bias-variance tradeoff in tuning this forest. For what values of the tuning parameter will forests be the most biased? The most variable?</p></li>
</ol>
</div>
<div id="exercise-5-evaluating-the-forest" class="section level3 unnumbered hasAnchor">
<h3>Exercise 5: Evaluating the forest<a href="bagging-and-random-forests.html#exercise-5-evaluating-the-forest" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The code below prints information pertaining to the “best” forest model.</p>
<div class="sourceCode" id="cb126"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb126-1"><a href="bagging-and-random-forests.html#cb126-1" aria-hidden="true" tabindex="-1"></a>rf_mod<span class="sc">$</span>finalModel</span></code></pre></div>
<ol style="list-style-type: lower-alpha">
<li>Report and interpret the <code>OOB prediction error</code>. (How does this match up with the plot from the previous exercise?)</li>
</ol>
<div class="sourceCode" id="cb127"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb127-1"><a href="bagging-and-random-forests.html#cb127-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rf_OOB_output</span>(data_fit_mtry12,<span class="dv">12</span>, land <span class="sc">%&gt;%</span> <span class="fu">pull</span>(class)) <span class="sc">%&gt;%</span></span>
<span id="cb127-2"><a href="bagging-and-random-forests.html#cb127-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">conf_mat</span>(<span class="at">truth =</span> class, <span class="at">estimate=</span> .pred_class)</span></code></pre></div>
<ol start="2" style="list-style-type: lower-alpha">
<li><p>The output includes an OOB test confusion matrix (as opposed to a training confusion matrix). Rows are true classes, and columns are predicted classes. How do you think this is constructed? Why is the test confusion matrix preferable to a training confusion matrix?</p></li>
<li><p>Further inspecting the test confusion matrix, which type of land use is most accurately classified by our forest? Which type of land use is least accurately classified by our forest? Why do you think this is?</p></li>
<li><p>In our previous activities, our best tree had a cross-validated accuracy rate of around 85%. How does the forest performance compare?</p></li>
</ol>
</div>
<div id="exercise-6-variable-importance-measures" class="section level3 unnumbered hasAnchor">
<h3>Exercise 6: Variable importance measures<a href="bagging-and-random-forests.html#exercise-6-variable-importance-measures" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Because bagging and random forests use tons of trees, the nice interpretability of single decision trees is lost. However, we can still get a measure of how important the different predictors were in this classification task.</p>
<p>There are two main importance measures.</p>
<p><em>Impurity</em>: For each of the 147 predictors, the code below gives the “total decrease in node impurities (as measured by the Gini index) from splitting on the variable, averaged over all trees”.</p>
<div class="sourceCode" id="cb128"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb128-1"><a href="bagging-and-random-forests.html#cb128-1" aria-hidden="true" tabindex="-1"></a>model_output <span class="ot">&lt;-</span>data_fit_mtry12 <span class="sc">%&gt;%</span> </span>
<span id="cb128-2"><a href="bagging-and-random-forests.html#cb128-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">extract_fit_engine</span>() </span>
<span id="cb128-3"><a href="bagging-and-random-forests.html#cb128-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb128-4"><a href="bagging-and-random-forests.html#cb128-4" aria-hidden="true" tabindex="-1"></a>model_output <span class="sc">%&gt;%</span> </span>
<span id="cb128-5"><a href="bagging-and-random-forests.html#cb128-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">vip</span>(<span class="at">num_features =</span> <span class="dv">30</span>) <span class="sc">+</span> <span class="fu">theme_classic</span>() <span class="co">#based on impurity</span></span>
<span id="cb128-6"><a href="bagging-and-random-forests.html#cb128-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb128-7"><a href="bagging-and-random-forests.html#cb128-7" aria-hidden="true" tabindex="-1"></a>model_output <span class="sc">%&gt;%</span> vip<span class="sc">::</span><span class="fu">vi</span>() <span class="sc">%&gt;%</span> <span class="fu">head</span>()</span>
<span id="cb128-8"><a href="bagging-and-random-forests.html#cb128-8" aria-hidden="true" tabindex="-1"></a>model_output <span class="sc">%&gt;%</span> vip<span class="sc">::</span><span class="fu">vi</span>() <span class="sc">%&gt;%</span> <span class="fu">tail</span>()</span></code></pre></div>
<p>*a. Check out the codebook for these variables <a href="https://archive.ics.uci.edu/ml/datasets/Urban+Land+Cover">here</a>. The descriptions of the variables aren’t the greatest, but does this ranking make some contextual sense?</p>
<ol start="2" style="list-style-type: lower-alpha">
<li><p>Construct some visualizations of the 1 most and 1 least important predictors that support your conclusion in a.</p></li>
<li><p>It has been found that this random forest measure of variable importance can tend to favor predictors with a lot of unique values. Explain briefly why it makes sense that this can happen by thinking about the recursive binary splitting algorithm for a single tree. (Note: similar cautions arise for variable importance in single trees.)</p></li>
</ol>
<p><em>Permutation</em>: We consider a variable important if it has a positive effect on the prediction performance. To evaluate this, first, a tree is grown and the prediction accuracy in the OOB observations is calculated. In the second step, any association between the variable and the outcome is broken by permuting the values of all individuals that vairable, and the prediction accuracy is computed again. The difference between the two accuracy values is the permutation importance the variable from a single tree. The average of all tree importance values in a random forest then gives the random forest permutation importance of this variable. The procedure is repeated for all variables of interest.</p>
<div class="sourceCode" id="cb129"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb129-1"><a href="bagging-and-random-forests.html#cb129-1" aria-hidden="true" tabindex="-1"></a>model_output2 <span class="ot">&lt;-</span> data_wf_mtry12 <span class="sc">%&gt;%</span> </span>
<span id="cb129-2"><a href="bagging-and-random-forests.html#cb129-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">update_model</span>(rf_spec <span class="sc">%&gt;%</span> <span class="fu">set_args</span>(<span class="at">importance =</span> <span class="st">&quot;permutation&quot;</span>)) <span class="sc">%&gt;%</span> <span class="co">#based on permutation</span></span>
<span id="cb129-3"><a href="bagging-and-random-forests.html#cb129-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">data =</span> land) <span class="sc">%&gt;%</span> </span>
<span id="cb129-4"><a href="bagging-and-random-forests.html#cb129-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">extract_fit_engine</span>() </span>
<span id="cb129-5"><a href="bagging-and-random-forests.html#cb129-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb129-6"><a href="bagging-and-random-forests.html#cb129-6" aria-hidden="true" tabindex="-1"></a>model_output2 <span class="sc">%&gt;%</span> </span>
<span id="cb129-7"><a href="bagging-and-random-forests.html#cb129-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">vip</span>(<span class="at">num_features =</span> <span class="dv">30</span>) <span class="sc">+</span> <span class="fu">theme_classic</span>()</span>
<span id="cb129-8"><a href="bagging-and-random-forests.html#cb129-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb129-9"><a href="bagging-and-random-forests.html#cb129-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb129-10"><a href="bagging-and-random-forests.html#cb129-10" aria-hidden="true" tabindex="-1"></a>model_output2 <span class="sc">%&gt;%</span> vip<span class="sc">::</span><span class="fu">vi</span>() <span class="sc">%&gt;%</span> <span class="fu">head</span>()</span>
<span id="cb129-11"><a href="bagging-and-random-forests.html#cb129-11" aria-hidden="true" tabindex="-1"></a>model_output2 <span class="sc">%&gt;%</span> vip<span class="sc">::</span><span class="fu">vi</span>() <span class="sc">%&gt;%</span> <span class="fu">tail</span>()</span></code></pre></div>
<ol style="list-style-type: lower-alpha">
<li><p>Check out the codebook for these variables <a href="https://archive.ics.uci.edu/ml/datasets/Urban+Land+Cover">here</a>. The descriptions of the variables aren’t the greatest, but do these rankings make some contextual sense?</p></li>
<li><p>Construct some visualizations of the 1 most and 1 least important predictors that support your conclusion in a.</p></li>
<li><p>It has been found that the impurity random forest measure of variable importance can tend to favor predictors with a lot of unique values. Explain briefly why it makes sense that this can happen by thinking about the recursive binary splitting algorithm for a single tree. (Note: similar cautions arise for variable importance in single trees.)</p></li>
</ol>

</div>
</div>
</div>



            </section>

          </div>
        </div>
      </div>
<a href="decision-trees.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="homework-1.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
