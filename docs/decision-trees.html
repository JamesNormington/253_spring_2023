<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Topic 12 Decision Trees | STAT 253: Statistical Machine Learning</title>
  <meta name="description" content="This is the class website for Statistical Machine Learning at Macalester College." />
  <meta name="generator" content="bookdown 0.32 and GitBook 2.6.7" />

  <meta property="og:title" content="Topic 12 Decision Trees | STAT 253: Statistical Machine Learning" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is the class website for Statistical Machine Learning at Macalester College." />
  <meta name="github-repo" content="JamesNormington/253_spring_2023" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Topic 12 Decision Trees | STAT 253: Statistical Machine Learning" />
  
  <meta name="twitter:description" content="This is the class website for Statistical Machine Learning at Macalester College." />
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="lasso-logistic-regression.html"/>
<link rel="next" href="bagging-and-random-forests.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="custom_styles.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href = "./">STAT 253: Statistical Machine Learning</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome!</a></li>
<li class="chapter" data-level="" data-path="schedule-syllabus.html"><a href="schedule-syllabus.html"><i class="fa fa-check"></i>Schedule &amp; Syllabus</a></li>
<li class="chapter" data-level="" data-path="learning-objectives.html"><a href="learning-objectives.html"><i class="fa fa-check"></i>Learning Objectives</a></li>
<li class="chapter" data-level="" data-path="r-and-rstudio-setup.html"><a href="r-and-rstudio-setup.html"><i class="fa fa-check"></i>R and RStudio Setup</a>
<ul>
<li class="chapter" data-level="" data-path="r-and-rstudio-setup.html"><a href="r-and-rstudio-setup.html#troubleshooting"><i class="fa fa-check"></i>Troubleshooting</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introductions.html"><a href="introductions.html"><i class="fa fa-check"></i><b>1</b> Introductions</a>
<ul>
<li class="chapter" data-level="" data-path="introductions.html"><a href="introductions.html#envisioning-a-community-of-learners"><i class="fa fa-check"></i>Envisioning a Community of Learners</a></li>
<li class="chapter" data-level="" data-path="introductions.html"><a href="introductions.html#explorations"><i class="fa fa-check"></i>Explorations</a></li>
</ul></li>
<li class="part"><span><b>I Regression: Evaluation</b></span></li>
<li class="chapter" data-level="2" data-path="evaluating-regression-models.html"><a href="evaluating-regression-models.html"><i class="fa fa-check"></i><b>2</b> Evaluating Regression Models</a>
<ul>
<li class="chapter" data-level="" data-path="evaluating-regression-models.html"><a href="evaluating-regression-models.html#learning-goals"><i class="fa fa-check"></i>Learning Goals</a></li>
<li class="chapter" data-level="" data-path="evaluating-regression-models.html"><a href="evaluating-regression-models.html#exercises"><i class="fa fa-check"></i>Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="evaluating-regression-models.html"><a href="evaluating-regression-models.html#context"><i class="fa fa-check"></i>Context</a></li>
<li class="chapter" data-level="" data-path="evaluating-regression-models.html"><a href="evaluating-regression-models.html#class-investigations"><i class="fa fa-check"></i>Class investigations</a></li>
<li class="chapter" data-level="" data-path="evaluating-regression-models.html"><a href="evaluating-regression-models.html#exercise-1"><i class="fa fa-check"></i>Exercise 1</a></li>
<li class="chapter" data-level="" data-path="evaluating-regression-models.html"><a href="evaluating-regression-models.html#exercise-2"><i class="fa fa-check"></i>Exercise 2</a></li>
<li class="chapter" data-level="" data-path="evaluating-regression-models.html"><a href="evaluating-regression-models.html#exercise-3"><i class="fa fa-check"></i>Exercise 3</a></li>
<li class="chapter" data-level="" data-path="evaluating-regression-models.html"><a href="evaluating-regression-models.html#exercise-4"><i class="fa fa-check"></i>Exercise 4</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="overfitting.html"><a href="overfitting.html"><i class="fa fa-check"></i><b>3</b> Overfitting</a>
<ul>
<li class="chapter" data-level="" data-path="overfitting.html"><a href="overfitting.html#learning-goals-1"><i class="fa fa-check"></i>Learning Goals</a></li>
<li class="chapter" data-level="" data-path="overfitting.html"><a href="overfitting.html#the-tidymodels-package"><i class="fa fa-check"></i>The <code>tidymodels</code> package</a></li>
<li class="chapter" data-level="" data-path="overfitting.html"><a href="overfitting.html#exercises-1"><i class="fa fa-check"></i>Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="overfitting.html"><a href="overfitting.html#context-1"><i class="fa fa-check"></i>Context</a></li>
<li class="chapter" data-level="" data-path="overfitting.html"><a href="overfitting.html#exercise-1-5-models"><i class="fa fa-check"></i>Exercise 1: 5 models</a></li>
<li class="chapter" data-level="" data-path="overfitting.html"><a href="overfitting.html#exercise-2-evaluating-the-test-data"><i class="fa fa-check"></i>Exercise 2: Evaluating the Test Data</a></li>
<li class="chapter" data-level="" data-path="overfitting.html"><a href="overfitting.html#exercise-3-overfitting"><i class="fa fa-check"></i>Exercise 3: Overfitting</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="cross-validation.html"><a href="cross-validation.html"><i class="fa fa-check"></i><b>4</b> Cross-validation</a>
<ul>
<li class="chapter" data-level="" data-path="cross-validation.html"><a href="cross-validation.html#learning-goals-2"><i class="fa fa-check"></i>Learning Goals</a></li>
<li class="chapter" data-level="" data-path="cross-validation.html"><a href="cross-validation.html#exercises-2"><i class="fa fa-check"></i>Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="cross-validation.html"><a href="cross-validation.html#context-2"><i class="fa fa-check"></i>Context</a></li>
<li class="chapter" data-level="" data-path="cross-validation.html"><a href="cross-validation.html#exercise-1-cross-validation-in-concept"><i class="fa fa-check"></i>Exercise 1: Cross-validation in Concept</a></li>
<li class="chapter" data-level="" data-path="cross-validation.html"><a href="cross-validation.html#exercise-2-cross-validation-with-tidymodels"><i class="fa fa-check"></i>Exercise 2: Cross-validation with <code>tidymodels</code></a></li>
<li class="chapter" data-level="" data-path="cross-validation.html"><a href="cross-validation.html#exercise-3-looking-at-the-evaluation-metrics"><i class="fa fa-check"></i>Exercise 3: Looking at the evaluation metrics</a></li>
<li class="chapter" data-level="" data-path="cross-validation.html"><a href="cross-validation.html#exercise-4-practical-issues-choosing-k"><i class="fa fa-check"></i>Exercise 4: Practical issues: choosing <span class="math inline">\(k\)</span></a></li>
<li class="chapter" data-level="" data-path="cross-validation.html"><a href="cross-validation.html#digging-deeper"><i class="fa fa-check"></i>Digging deeper</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Regression: Building Models</b></span></li>
<li class="chapter" data-level="5" data-path="variable-subset-selection.html"><a href="variable-subset-selection.html"><i class="fa fa-check"></i><b>5</b> Variable Subset Selection</a>
<ul>
<li class="chapter" data-level="" data-path="variable-subset-selection.html"><a href="variable-subset-selection.html#learning-goals-3"><i class="fa fa-check"></i>Learning Goals</a></li>
<li class="chapter" data-level="" data-path="variable-subset-selection.html"><a href="variable-subset-selection.html#exercises-3"><i class="fa fa-check"></i>Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="variable-subset-selection.html"><a href="variable-subset-selection.html#exercise-1-backward-stepwise-selection-by-hand"><i class="fa fa-check"></i>Exercise 1: Backward stepwise selection: by hand</a></li>
<li class="chapter" data-level="" data-path="variable-subset-selection.html"><a href="variable-subset-selection.html#exercise-2-interpreting-the-results"><i class="fa fa-check"></i>Exercise 2: Interpreting the results</a></li>
<li class="chapter" data-level="" data-path="variable-subset-selection.html"><a href="variable-subset-selection.html#exercise-3-planning-forward-selection-using-cv"><i class="fa fa-check"></i>Exercise 3: Planning forward selection using CV</a></li>
<li class="chapter" data-level="" data-path="variable-subset-selection.html"><a href="variable-subset-selection.html#exercise-4-stepwise-selection-in-caret"><i class="fa fa-check"></i>Exercise 4: Stepwise selection in <code>caret</code></a></li>
<li class="chapter" data-level="" data-path="variable-subset-selection.html"><a href="variable-subset-selection.html#exercise-5-exploring-the-results"><i class="fa fa-check"></i>Exercise 5: Exploring the results</a></li>
<li class="chapter" data-level="" data-path="variable-subset-selection.html"><a href="variable-subset-selection.html#digging-deeper-1"><i class="fa fa-check"></i>Digging deeper</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="lasso-shrinkageregularization.html"><a href="lasso-shrinkageregularization.html"><i class="fa fa-check"></i><b>6</b> LASSO: Shrinkage/Regularization</a>
<ul>
<li class="chapter" data-level="" data-path="lasso-shrinkageregularization.html"><a href="lasso-shrinkageregularization.html#learning-goals-4"><i class="fa fa-check"></i>Learning Goals</a></li>
<li class="chapter" data-level="" data-path="lasso-shrinkageregularization.html"><a href="lasso-shrinkageregularization.html#lasso-models-in-tidymodels"><i class="fa fa-check"></i>LASSO models in <code>tidymodels</code></a></li>
<li class="chapter" data-level="" data-path="lasso-shrinkageregularization.html"><a href="lasso-shrinkageregularization.html#exercises-4"><i class="fa fa-check"></i>Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="lasso-shrinkageregularization.html"><a href="lasso-shrinkageregularization.html#exercise-1-a-least-squares-model"><i class="fa fa-check"></i>Exercise 1: A least squares model</a></li>
<li class="chapter" data-level="" data-path="lasso-shrinkageregularization.html"><a href="lasso-shrinkageregularization.html#exercise-2-fitting-a-lasso-model-in-tidymodels"><i class="fa fa-check"></i>Exercise 2: Fitting a LASSO model in <code>tidymodels</code></a></li>
<li class="chapter" data-level="" data-path="lasso-shrinkageregularization.html"><a href="lasso-shrinkageregularization.html#exercise-3-examining-output-plot-of-coefficient-paths"><i class="fa fa-check"></i>Exercise 3: Examining output: plot of coefficient paths</a></li>
<li class="chapter" data-level="" data-path="lasso-shrinkageregularization.html"><a href="lasso-shrinkageregularization.html#exercise-4-examining-and-evaluating-the-best-lasso-model."><i class="fa fa-check"></i>Exercise 4: Examining and evaluating the best LASSO model.</a></li>
<li class="chapter" data-level="" data-path="lasso-shrinkageregularization.html"><a href="lasso-shrinkageregularization.html#digging-deeper-2"><i class="fa fa-check"></i>Digging deeper</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Regression: Building Flexible Models</b></span></li>
<li class="chapter" data-level="7" data-path="knn-regression-and-the-bias-variance-tradeoff.html"><a href="knn-regression-and-the-bias-variance-tradeoff.html"><i class="fa fa-check"></i><b>7</b> KNN Regression and the Bias-Variance Tradeoff</a>
<ul>
<li class="chapter" data-level="" data-path="knn-regression-and-the-bias-variance-tradeoff.html"><a href="knn-regression-and-the-bias-variance-tradeoff.html#learning-goals-5"><i class="fa fa-check"></i>Learning Goals</a></li>
<li class="chapter" data-level="" data-path="knn-regression-and-the-bias-variance-tradeoff.html"><a href="knn-regression-and-the-bias-variance-tradeoff.html#knn-models-in-tidymodels"><i class="fa fa-check"></i>KNN models in <code>tidymodels</code></a></li>
<li class="chapter" data-level="" data-path="knn-regression-and-the-bias-variance-tradeoff.html"><a href="knn-regression-and-the-bias-variance-tradeoff.html#exercises-5"><i class="fa fa-check"></i>Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="knn-regression-and-the-bias-variance-tradeoff.html"><a href="knn-regression-and-the-bias-variance-tradeoff.html#exercise-1-bias-variance-tradeoff-warmup"><i class="fa fa-check"></i>Exercise 1: Bias-variance tradeoff warmup</a></li>
<li class="chapter" data-level="" data-path="knn-regression-and-the-bias-variance-tradeoff.html"><a href="knn-regression-and-the-bias-variance-tradeoff.html#exercise-2-impact-of-distance-metric"><i class="fa fa-check"></i>Exercise 2: Impact of distance metric</a></li>
<li class="chapter" data-level="" data-path="knn-regression-and-the-bias-variance-tradeoff.html"><a href="knn-regression-and-the-bias-variance-tradeoff.html#exercise-3-implementing-knn-in-tidymodels"><i class="fa fa-check"></i>Exercise 3: Implementing KNN in <code>tidymodels</code></a></li>
<li class="chapter" data-level="" data-path="knn-regression-and-the-bias-variance-tradeoff.html"><a href="knn-regression-and-the-bias-variance-tradeoff.html#exercise-4-inspecting-the-results"><i class="fa fa-check"></i>Exercise 4: Inspecting the results</a></li>
<li class="chapter" data-level="" data-path="knn-regression-and-the-bias-variance-tradeoff.html"><a href="knn-regression-and-the-bias-variance-tradeoff.html#exercise-5-curse-of-dimensionality"><i class="fa fa-check"></i>Exercise 5: Curse of dimensionality</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="splines.html"><a href="splines.html"><i class="fa fa-check"></i><b>8</b> Splines</a>
<ul>
<li class="chapter" data-level="" data-path="splines.html"><a href="splines.html#learning-goals-6"><i class="fa fa-check"></i>Learning Goals</a></li>
<li class="chapter" data-level="" data-path="splines.html"><a href="splines.html#splines-in-tidymodels"><i class="fa fa-check"></i>Splines in <code>tidymodels</code></a></li>
<li class="chapter" data-level="" data-path="splines.html"><a href="splines.html#exercises-6"><i class="fa fa-check"></i>Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="splines.html"><a href="splines.html#exercise-1-evaluating-a-fully-linear-model"><i class="fa fa-check"></i>Exercise 1: Evaluating a fully linear model</a></li>
<li class="chapter" data-level="" data-path="splines.html"><a href="splines.html#exercise-2-evaluating-a-spline-model"><i class="fa fa-check"></i>Exercise 2: Evaluating a spline model</a></li>
<li class="chapter" data-level="" data-path="splines.html"><a href="splines.html#extra-variable-scaling"><i class="fa fa-check"></i>Extra! Variable scaling</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="local-regression-gams.html"><a href="local-regression-gams.html"><i class="fa fa-check"></i><b>9</b> Local Regression &amp; GAMs</a>
<ul>
<li class="chapter" data-level="" data-path="local-regression-gams.html"><a href="local-regression-gams.html#learning-goals-7"><i class="fa fa-check"></i>Learning Goals</a></li>
<li class="chapter" data-level="9.1" data-path="local-regression-gams.html"><a href="local-regression-gams.html#gams"><i class="fa fa-check"></i><b>9.1</b> GAMs</a></li>
<li class="chapter" data-level="9.2" data-path="local-regression-gams.html"><a href="local-regression-gams.html#gams---options-for-fitting"><i class="fa fa-check"></i><b>9.2</b> GAMs - Options for Fitting</a></li>
<li class="chapter" data-level="" data-path="local-regression-gams.html"><a href="local-regression-gams.html#gams-in-tidymodels"><i class="fa fa-check"></i>GAMs in <code>tidymodels</code></a></li>
<li class="chapter" data-level="" data-path="local-regression-gams.html"><a href="local-regression-gams.html#exercises-7"><i class="fa fa-check"></i>Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="local-regression-gams.html"><a href="local-regression-gams.html#exercise-1-conceptual-warmup"><i class="fa fa-check"></i>Exercise 1: Conceptual warmup</a></li>
<li class="chapter" data-level="" data-path="local-regression-gams.html"><a href="local-regression-gams.html#exercise-2-using-loess"><i class="fa fa-check"></i>Exercise 2: Using LOESS</a></li>
<li class="chapter" data-level="" data-path="local-regression-gams.html"><a href="local-regression-gams.html#exercise-3-building-a-gam-in-tidymodels"><i class="fa fa-check"></i>Exercise 3: Building a GAM in <code>tidymodels</code></a></li>
<li class="chapter" data-level="" data-path="local-regression-gams.html"><a href="local-regression-gams.html#exercise-4-adjusting-the-best-gam"><i class="fa fa-check"></i>Exercise 4: Adjusting the “best” GAM</a></li>
<li class="chapter" data-level="" data-path="local-regression-gams.html"><a href="local-regression-gams.html#exercise-5-gam-with-recipes"><i class="fa fa-check"></i>Exercise 5: GAM with recipes</a></li>
<li class="chapter" data-level="" data-path="local-regression-gams.html"><a href="local-regression-gams.html#exercise-6-putting-a-bow-on-regression"><i class="fa fa-check"></i>Exercise 6: putting a bow on regression</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IV Classification</b></span></li>
<li class="chapter" data-level="10" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>10</b> Logistic Regression</a>
<ul>
<li class="chapter" data-level="" data-path="logistic-regression.html"><a href="logistic-regression.html#learning-goals-8"><i class="fa fa-check"></i>Learning Goals</a></li>
<li class="chapter" data-level="" data-path="logistic-regression.html"><a href="logistic-regression.html#logistic-regression-in-tidymodels"><i class="fa fa-check"></i>Logistic regression in <code>tidymodels</code></a></li>
<li class="chapter" data-level="" data-path="logistic-regression.html"><a href="logistic-regression.html#exercises-8"><i class="fa fa-check"></i>Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="logistic-regression.html"><a href="logistic-regression.html#context-and-data"><i class="fa fa-check"></i>Context and Data</a></li>
<li class="chapter" data-level="" data-path="logistic-regression.html"><a href="logistic-regression.html#exercise-1-visualization-warmup"><i class="fa fa-check"></i>Exercise 1: Visualization warmup</a></li>
<li class="chapter" data-level="" data-path="logistic-regression.html"><a href="logistic-regression.html#exercise-2-implementing-logistic-regression-in-tidymodels"><i class="fa fa-check"></i>Exercise 2: Implementing logistic regression in <code>tidymodels</code></a></li>
<li class="chapter" data-level="" data-path="logistic-regression.html"><a href="logistic-regression.html#exercise-3-interpreting-the-model"><i class="fa fa-check"></i>Exercise 3: Interpreting the model</a></li>
<li class="chapter" data-level="" data-path="logistic-regression.html"><a href="logistic-regression.html#exercise-4-making-predictions"><i class="fa fa-check"></i>Exercise 4: Making predictions</a></li>
<li class="chapter" data-level="10.0.1" data-path="logistic-regression.html"><a href="logistic-regression.html#exercise-5-evaluate-the-model"><i class="fa fa-check"></i><b>10.0.1</b> Exercise 5: Evaluate the model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="lasso-logistic-regression.html"><a href="lasso-logistic-regression.html"><i class="fa fa-check"></i><b>11</b> Lasso &amp; Logistic Regression</a>
<ul>
<li class="chapter" data-level="" data-path="lasso-logistic-regression.html"><a href="lasso-logistic-regression.html#learning-goals-9"><i class="fa fa-check"></i>Learning Goals</a></li>
<li class="chapter" data-level="" data-path="lasso-logistic-regression.html"><a href="lasso-logistic-regression.html#lasso-for-logistic-regression-in-tidymodels"><i class="fa fa-check"></i>LASSO for logistic regression in <code>tidymodels</code></a></li>
<li class="chapter" data-level="" data-path="lasso-logistic-regression.html"><a href="lasso-logistic-regression.html#exercises-9"><i class="fa fa-check"></i>Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="lasso-logistic-regression.html"><a href="lasso-logistic-regression.html#context-3"><i class="fa fa-check"></i>Context</a></li>
<li class="chapter" data-level="" data-path="lasso-logistic-regression.html"><a href="lasso-logistic-regression.html#exercise-1-conceptual-warmup-1"><i class="fa fa-check"></i>Exercise 1: Conceptual warmup</a></li>
<li class="chapter" data-level="" data-path="lasso-logistic-regression.html"><a href="lasso-logistic-regression.html#exercise-2-implementing-lasso-logistic-regression-in-tidymodels"><i class="fa fa-check"></i>Exercise 2: Implementing LASSO logistic regression in <code>tidymodels</code></a></li>
<li class="chapter" data-level="" data-path="lasso-logistic-regression.html"><a href="lasso-logistic-regression.html#exercise-3-inspecting-the-model"><i class="fa fa-check"></i>Exercise 3: Inspecting the model</a></li>
<li class="chapter" data-level="" data-path="lasso-logistic-regression.html"><a href="lasso-logistic-regression.html#exercise-4-interpreting-evaluation-metrics"><i class="fa fa-check"></i>Exercise 4: Interpreting evaluation metrics</a></li>
<li class="chapter" data-level="" data-path="lasso-logistic-regression.html"><a href="lasso-logistic-regression.html#exercise-5-using-the-final-model-choosing-a-threshold"><i class="fa fa-check"></i>Exercise 5: Using the final model (choosing a threshold)</a></li>
<li class="chapter" data-level="" data-path="lasso-logistic-regression.html"><a href="lasso-logistic-regression.html#exercise-6-algorithmic-understanding-for-evaluation-metrics"><i class="fa fa-check"></i>Exercise 6: Algorithmic understanding for evaluation metrics</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="decision-trees.html"><a href="decision-trees.html"><i class="fa fa-check"></i><b>12</b> Decision Trees</a>
<ul>
<li class="chapter" data-level="" data-path="decision-trees.html"><a href="decision-trees.html#learning-goals-10"><i class="fa fa-check"></i>Learning Goals</a></li>
<li class="chapter" data-level="" data-path="decision-trees.html"><a href="decision-trees.html#trees-in-tidymodels"><i class="fa fa-check"></i>Trees in <code>tidymodels</code></a></li>
<li class="chapter" data-level="" data-path="decision-trees.html"><a href="decision-trees.html#exercises-part-1"><i class="fa fa-check"></i>Exercises Part 1</a>
<ul>
<li class="chapter" data-level="" data-path="decision-trees.html"><a href="decision-trees.html#context-4"><i class="fa fa-check"></i>Context</a></li>
<li class="chapter" data-level="" data-path="decision-trees.html"><a href="decision-trees.html#exercise-1-core-theme-parametricnonparametric"><i class="fa fa-check"></i>Exercise 1: Core theme: parametric/nonparametric</a></li>
<li class="chapter" data-level="" data-path="decision-trees.html"><a href="decision-trees.html#exercise-2-core-theme-tuning-parameters-and-the-bvt"><i class="fa fa-check"></i>Exercise 2: Core theme: Tuning parameters and the BVT</a></li>
<li class="chapter" data-level="" data-path="decision-trees.html"><a href="decision-trees.html#exercise-3-building-trees-in-tidymodels"><i class="fa fa-check"></i>Exercise 3: Building trees in <code>tidymodels</code></a></li>
<li class="chapter" data-level="" data-path="decision-trees.html"><a href="decision-trees.html#exercise-4-visualizing-trees"><i class="fa fa-check"></i>Exercise 4: Visualizing trees</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="decision-trees.html"><a href="decision-trees.html#exercises-part-2"><i class="fa fa-check"></i>Exercises Part 2</a>
<ul>
<li class="chapter" data-level="" data-path="decision-trees.html"><a href="decision-trees.html#exercise-5-predictions-from-trees"><i class="fa fa-check"></i>Exercise 5: Predictions from Trees</a></li>
<li class="chapter" data-level="" data-path="decision-trees.html"><a href="decision-trees.html#exercise-6-variable-importance-in-trees"><i class="fa fa-check"></i>Exercise 6: Variable importance in trees</a></li>
<li class="chapter" data-level="" data-path="decision-trees.html"><a href="decision-trees.html#exercise-7-regression-trees"><i class="fa fa-check"></i>Exercise 7: REGRESSION trees?!</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="bagging-and-random-forests.html"><a href="bagging-and-random-forests.html"><i class="fa fa-check"></i><b>13</b> Bagging and Random Forests</a>
<ul>
<li class="chapter" data-level="" data-path="bagging-and-random-forests.html"><a href="bagging-and-random-forests.html#learning-goals-11"><i class="fa fa-check"></i>Learning Goals</a></li>
<li class="chapter" data-level="" data-path="bagging-and-random-forests.html"><a href="bagging-and-random-forests.html#exercises-10"><i class="fa fa-check"></i>Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="bagging-and-random-forests.html"><a href="bagging-and-random-forests.html#exercise-1-bagging-bootstrap-aggregation"><i class="fa fa-check"></i>Exercise 1: Bagging: <em>B</em>ootstrap <em>AGG</em>regation</a></li>
<li class="chapter" data-level="" data-path="bagging-and-random-forests.html"><a href="bagging-and-random-forests.html#exercise-2-random-forest-groundwork"><i class="fa fa-check"></i>Exercise 2: Random forest groundwork</a></li>
<li class="chapter" data-level="" data-path="bagging-and-random-forests.html"><a href="bagging-and-random-forests.html#exercise-3-building-the-random-forest"><i class="fa fa-check"></i>Exercise 3: Building the random forest</a></li>
<li class="chapter" data-level="" data-path="bagging-and-random-forests.html"><a href="bagging-and-random-forests.html#exercise-4-preliminary-interpretation"><i class="fa fa-check"></i>Exercise 4: Preliminary interpretation</a></li>
<li class="chapter" data-level="" data-path="bagging-and-random-forests.html"><a href="bagging-and-random-forests.html#exercise-5-evaluating-the-forest"><i class="fa fa-check"></i>Exercise 5: Evaluating the forest</a></li>
<li class="chapter" data-level="" data-path="bagging-and-random-forests.html"><a href="bagging-and-random-forests.html#exercise-6-variable-importance-measures"><i class="fa fa-check"></i>Exercise 6: Variable importance measures</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>V Homework</b></span></li>
<li class="chapter" data-level="" data-path="homework-1.html"><a href="homework-1.html"><i class="fa fa-check"></i>Homework 1</a>
<ul>
<li class="chapter" data-level="" data-path="homework-1.html"><a href="homework-1.html#project-work"><i class="fa fa-check"></i>Project Work</a></li>
<li class="chapter" data-level="" data-path="homework-1.html"><a href="homework-1.html#ethics-in-ml"><i class="fa fa-check"></i>Ethics in ML</a></li>
<li class="chapter" data-level="" data-path="homework-1.html"><a href="homework-1.html#portfolio-work"><i class="fa fa-check"></i>Portfolio Work</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="homework-2.html"><a href="homework-2.html"><i class="fa fa-check"></i>Homework 2</a>
<ul>
<li class="chapter" data-level="" data-path="homework-2.html"><a href="homework-2.html#project-work-1"><i class="fa fa-check"></i>Project Work</a></li>
<li class="chapter" data-level="" data-path="homework-2.html"><a href="homework-2.html#ethics-in-ml-1"><i class="fa fa-check"></i>Ethics in ML</a></li>
<li class="chapter" data-level="" data-path="homework-2.html"><a href="homework-2.html#portfolio-work-1"><i class="fa fa-check"></i>Portfolio Work</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="homework-3.html"><a href="homework-3.html"><i class="fa fa-check"></i>Homework 3</a>
<ul>
<li class="chapter" data-level="" data-path="homework-3.html"><a href="homework-3.html#project-work-2"><i class="fa fa-check"></i>Project Work</a>
<ul>
<li class="chapter" data-level="" data-path="homework-3.html"><a href="homework-3.html#note-this-is-a-repeat-of-hw2.-many-of-you-struggled-with-this-section-so-this-gives-you-an-opportunity-to-incorporate-feedback-from-the-preceptors-or-try-additional-models."><i class="fa fa-check"></i>Note: this is a repeat of HW2. Many of you struggled with this section, so this gives you an opportunity to incorporate feedback from the preceptors, or try additional models.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="homework-3.html"><a href="homework-3.html#portfolio-work-2"><i class="fa fa-check"></i>Portfolio Work</a></li>
<li class="chapter" data-level="" data-path="homework-3.html"><a href="homework-3.html#ethics-in-ml-2"><i class="fa fa-check"></i>Ethics in ML</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="homework-4.html"><a href="homework-4.html"><i class="fa fa-check"></i>Homework 4</a>
<ul>
<li class="chapter" data-level="" data-path="homework-4.html"><a href="homework-4.html#project-work-3"><i class="fa fa-check"></i>Project Work</a></li>
<li class="chapter" data-level="" data-path="homework-4.html"><a href="homework-4.html#ethics-in-ml-3"><i class="fa fa-check"></i>Ethics in ML</a></li>
<li class="chapter" data-level="" data-path="homework-4.html"><a href="homework-4.html#portfolio-work-3"><i class="fa fa-check"></i>Portfolio Work</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="r-resources.html"><a href="r-resources.html"><i class="fa fa-check"></i>R Resources</a>
<ul>
<li class="chapter" data-level="" data-path="r-resources.html"><a href="r-resources.html#outside-resources"><i class="fa fa-check"></i>Outside resources</a></li>
<li class="chapter" data-level="" data-path="r-resources.html"><a href="r-resources.html#example-code"><i class="fa fa-check"></i>Example code</a></li>
</ul></li>
<li class="part"><span><b>VI Project</b></span></li>
<li class="chapter" data-level="" data-path="final-project.html"><a href="final-project.html"><i class="fa fa-check"></i>Final Project</a>
<ul>
<li class="chapter" data-level="" data-path="final-project.html"><a href="final-project.html#requirements"><i class="fa fa-check"></i>Requirements</a></li>
<li class="chapter" data-level="" data-path="final-project.html"><a href="final-project.html#grading-rubric"><i class="fa fa-check"></i>Grading Rubric</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">STAT 253: Statistical Machine Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="decision-trees" class="section level1 hasAnchor" number="12">
<h1><span class="header-section-number">Topic 12</span> Decision Trees<a href="decision-trees.html#decision-trees" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="learning-goals-10" class="section level2 unnumbered hasAnchor">
<h2>Learning Goals<a href="decision-trees.html#learning-goals-10" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li>Clearly describe the recursive binary splitting algorithm for tree building for both regression and classification</li>
<li>Compute the weighted average Gini index to measure the quality of a classification tree split</li>
<li>Compute the sum of squared residuals to measure the quality of a regression tree split</li>
<li>Explain how recursive binary splitting is a greedy algorithm</li>
<li>Explain how different tree parameters relate to the bias-variance tradeoff</li>
</ul>
<p><br></p>
<p>Slides from today are available <a href="https://docs.google.com/presentation/d/1olyNd3Etj5ad2hlwoP-6D_vsbiTe_kUU/edit?usp=sharing&amp;ouid=115583691606860124358&amp;rtpof=true&amp;sd=true">here</a>.</p>
<p><br><br><br></p>
</div>
<div id="trees-in-tidymodels" class="section level2 unnumbered hasAnchor">
<h2>Trees in <code>tidymodels</code><a href="decision-trees.html#trees-in-tidymodels" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>To build tree models in <code>tidymodels</code>, first load the package and set the seed for the random number generator to ensure reproducible results:</p>
<div class="sourceCode" id="cb108"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb108-1"><a href="decision-trees.html#cb108-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb108-2"><a href="decision-trees.html#cb108-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(readr)</span>
<span id="cb108-3"><a href="decision-trees.html#cb108-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb108-4"><a href="decision-trees.html#cb108-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidymodels)</span>
<span id="cb108-5"><a href="decision-trees.html#cb108-5" aria-hidden="true" tabindex="-1"></a><span class="fu">tidymodels_prefer</span>()</span>
<span id="cb108-6"><a href="decision-trees.html#cb108-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb108-7"><a href="decision-trees.html#cb108-7" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(___) <span class="co"># Pick your favorite number to fill in the parentheses</span></span></code></pre></div>
<p>To fit a decision tree, we can adapt the following:</p>
<div class="sourceCode" id="cb109"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb109-1"><a href="decision-trees.html#cb109-1" aria-hidden="true" tabindex="-1"></a>ct_spec <span class="ot">&lt;-</span> <span class="fu">decision_tree</span>() <span class="sc">%&gt;%</span></span>
<span id="cb109-2"><a href="decision-trees.html#cb109-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="at">engine =</span> <span class="st">&#39;rpart&#39;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb109-3"><a href="decision-trees.html#cb109-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_args</span>(<span class="at">cost_complexity =</span> <span class="cn">NULL</span>,  <span class="co">#default is 0.01 (used for pruning a tree)</span></span>
<span id="cb109-4"><a href="decision-trees.html#cb109-4" aria-hidden="true" tabindex="-1"></a>           <span class="at">min_n =</span> <span class="cn">NULL</span>, <span class="co">#min number of observations to try split: default is 20 [I think the documentation has a typo and says 2]  (used to stop early)</span></span>
<span id="cb109-5"><a href="decision-trees.html#cb109-5" aria-hidden="true" tabindex="-1"></a>           <span class="at">tree_depth =</span> <span class="cn">NULL</span>) <span class="sc">%&gt;%</span> <span class="co">#max depth, number of branches/splits to get to any final group: default is 30 (used to stop early)</span></span>
<span id="cb109-6"><a href="decision-trees.html#cb109-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&#39;classification&#39;</span>) <span class="co"># change this for regression tree</span></span>
<span id="cb109-7"><a href="decision-trees.html#cb109-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-8"><a href="decision-trees.html#cb109-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-9"><a href="decision-trees.html#cb109-9" aria-hidden="true" tabindex="-1"></a>data_rec <span class="ot">&lt;-</span> <span class="fu">recipe</span>(___ <span class="sc">~</span> ___, <span class="at">data =</span> ______)</span>
<span id="cb109-10"><a href="decision-trees.html#cb109-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-11"><a href="decision-trees.html#cb109-11" aria-hidden="true" tabindex="-1"></a>data_wf <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">%&gt;%</span></span>
<span id="cb109-12"><a href="decision-trees.html#cb109-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_model</span>(ct_spec) <span class="sc">%&gt;%</span></span>
<span id="cb109-13"><a href="decision-trees.html#cb109-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_recipe</span>(data_rec)</span>
<span id="cb109-14"><a href="decision-trees.html#cb109-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-15"><a href="decision-trees.html#cb109-15" aria-hidden="true" tabindex="-1"></a>fit_mod <span class="ot">&lt;-</span> data_wf <span class="sc">%&gt;%</span> <span class="co"># or use tune_grid() to tune any of the parameters above</span></span>
<span id="cb109-16"><a href="decision-trees.html#cb109-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">data =</span> _____)</span></code></pre></div>
<p><br></p>
<p><strong>Visualizing and interpreting the “best” tree</strong></p>
<div class="sourceCode" id="cb110"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb110-1"><a href="decision-trees.html#cb110-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the tree (make sure to load the rpart.plot package first)</span></span>
<span id="cb110-2"><a href="decision-trees.html#cb110-2" aria-hidden="true" tabindex="-1"></a>fit_mod <span class="sc">%&gt;%</span></span>
<span id="cb110-3"><a href="decision-trees.html#cb110-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">extract_fit_engine</span>() <span class="sc">%&gt;%</span></span>
<span id="cb110-4"><a href="decision-trees.html#cb110-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rpart.plot</span>()</span>
<span id="cb110-5"><a href="decision-trees.html#cb110-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb110-6"><a href="decision-trees.html#cb110-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Get variable importance metrics </span></span>
<span id="cb110-7"><a href="decision-trees.html#cb110-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Sum of the goodness of split measures (impurity reduction) for each split for which it was the primary variable.</span></span>
<span id="cb110-8"><a href="decision-trees.html#cb110-8" aria-hidden="true" tabindex="-1"></a>fit_mod <span class="sc">%&gt;%</span></span>
<span id="cb110-9"><a href="decision-trees.html#cb110-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">extract_fit_engine</span>() <span class="sc">%&gt;%</span></span>
<span id="cb110-10"><a href="decision-trees.html#cb110-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pluck</span>(<span class="st">&#39;variable.importance&#39;</span>)</span></code></pre></div>
<p><br><br><br></p>
</div>
<div id="exercises-part-1" class="section level2 unnumbered hasAnchor">
<h2>Exercises Part 1<a href="decision-trees.html#exercises-part-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><strong>You can download a template RMarkdown file to start from <a href="template_rmds/11-trees.Rmd">here</a>.</strong></p>
<div id="context-4" class="section level3 unnumbered hasAnchor">
<h3>Context<a href="decision-trees.html#context-4" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Before proceeding, install the <code>rpart</code> and <code>rpart.plot</code> packages (for building and plotting decision trees) by entering <code>install.packages(c("rpart", "rpart.plot"))</code> in the Console.</p>
<p>Our goal will be to classify types of urban land cover in small subregions within a high resolution aerial image of a land region. Data from the <a href="https://archive.ics.uci.edu/ml/datasets/Urban+Land+Cover">UCI Machine Learning Repository</a> include the observed type of land cover (determined by human eye) and “spectral, size, shape, and texture information” computed from the image. See <a href="https://archive.ics.uci.edu/ml/datasets/Urban+Land+Cover">this page</a> for the data codebook.</p>
<center>
<img src="https://ncap.org.uk/sites/default/files/EK_land_use_0.jpg"><br>
Source: <a href="https://ncap.org.uk/sites/default/files/EK_land_use_0.jpg" class="uri">https://ncap.org.uk/sites/default/files/EK_land_use_0.jpg</a>
</center>
<div class="sourceCode" id="cb111"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb111-1"><a href="decision-trees.html#cb111-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb111-2"><a href="decision-trees.html#cb111-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(readr)</span>
<span id="cb111-3"><a href="decision-trees.html#cb111-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb111-4"><a href="decision-trees.html#cb111-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart.plot)</span>
<span id="cb111-5"><a href="decision-trees.html#cb111-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidymodels)</span>
<span id="cb111-6"><a href="decision-trees.html#cb111-6" aria-hidden="true" tabindex="-1"></a><span class="fu">tidymodels_prefer</span>()</span>
<span id="cb111-7"><a href="decision-trees.html#cb111-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb111-8"><a href="decision-trees.html#cb111-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Read in the data</span></span>
<span id="cb111-9"><a href="decision-trees.html#cb111-9" aria-hidden="true" tabindex="-1"></a>land <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">&quot;https://ajohns24.github.io/portfolio/data/land_cover.csv&quot;</span>)</span>
<span id="cb111-10"><a href="decision-trees.html#cb111-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb111-11"><a href="decision-trees.html#cb111-11" aria-hidden="true" tabindex="-1"></a><span class="co"># There are 9 land types, but we&#39;ll focus on 3 of them</span></span>
<span id="cb111-12"><a href="decision-trees.html#cb111-12" aria-hidden="true" tabindex="-1"></a>land <span class="ot">&lt;-</span> land <span class="sc">%&gt;%</span> </span>
<span id="cb111-13"><a href="decision-trees.html#cb111-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">filter</span>(class <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">&quot;asphalt&quot;</span>, <span class="st">&quot;grass&quot;</span>, <span class="st">&quot;tree&quot;</span>))</span></code></pre></div>
</div>
<div id="exercise-1-core-theme-parametricnonparametric" class="section level3 unnumbered hasAnchor">
<h3>Exercise 1: Core theme: parametric/nonparametric<a href="decision-trees.html#exercise-1-core-theme-parametricnonparametric" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ol style="list-style-type: lower-alpha">
<li><p>What does it mean for a method to be nonparametric? In general, when might we prefer nonparametric to parametric methods? When might we not?</p></li>
<li><p>Where do you think trees fall on the parametric/nonparametric spectrum?</p></li>
</ol>
</div>
<div id="exercise-2-core-theme-tuning-parameters-and-the-bvt" class="section level3 unnumbered hasAnchor">
<h3>Exercise 2: Core theme: Tuning parameters and the BVT<a href="decision-trees.html#exercise-2-core-theme-tuning-parameters-and-the-bvt" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The key feature governing complexity of a tree model is the number of splits used in the tree. How is the number of splits related to model complexity, bias, and variance?</p>
<p>In practice, the number of splits is controlled indirectly through the following tuning parameters. For each, discuss how low/high parameter settings would affect the number of tree splits.</p>
<ul>
<li><p><code>min_n</code>: the minimum number of observations that must exist in a node in order for a split to be attempted.</p></li>
<li><p><code>cost_complexity</code>: complexity parameter. Any split that does not increase node purity by <code>cost_complexity</code> is not attempted.</p></li>
<li><p><code>depth</code>: Set the maximum <strong>depth</strong> of any node of the final tree. The <strong>depth</strong> of a node is the number of branches that need to be followed to get to a given node from the root node. (The root node has depth 0.)</p></li>
</ul>
</div>
<div id="exercise-3-building-trees-in-tidymodels" class="section level3 unnumbered hasAnchor">
<h3>Exercise 3: Building trees in <code>tidymodels</code><a href="decision-trees.html#exercise-3-building-trees-in-tidymodels" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Fit a tree model for the <code>class</code> outcome (land type), and allow all possible predictors to be considered (<code>~ .</code> in the model formula).</p>
<ul>
<li>Use 10-fold CV.</li>
<li>Choose a final model whose test overall accuracy is within one standard error of the overall best metric.</li>
<li>The Gini index impurity measure can be a minimum of zero and has an upper bound of 1.</li>
<li>Try a sequence of 30 <code>cost_complexity</code> values from 0.00001 to 0.1 (this will take up to 5 minutes).</li>
</ul>
<div class="sourceCode" id="cb112"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb112-1"><a href="decision-trees.html#cb112-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make sure you understand what each line of code is doing</span></span>
<span id="cb112-2"><a href="decision-trees.html#cb112-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>) <span class="co"># don&#39;t change this</span></span>
<span id="cb112-3"><a href="decision-trees.html#cb112-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb112-4"><a href="decision-trees.html#cb112-4" aria-hidden="true" tabindex="-1"></a>data_fold <span class="ot">&lt;-</span> <span class="fu">vfold_cv</span>(land, <span class="at">v =</span> <span class="dv">10</span>)</span>
<span id="cb112-5"><a href="decision-trees.html#cb112-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb112-6"><a href="decision-trees.html#cb112-6" aria-hidden="true" tabindex="-1"></a>ct_spec_tune <span class="ot">&lt;-</span> <span class="fu">decision_tree</span>() <span class="sc">%&gt;%</span></span>
<span id="cb112-7"><a href="decision-trees.html#cb112-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="at">engine =</span> <span class="st">&#39;rpart&#39;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb112-8"><a href="decision-trees.html#cb112-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_args</span>(<span class="at">cost_complexity =</span> <span class="fu">tune</span>(),  </span>
<span id="cb112-9"><a href="decision-trees.html#cb112-9" aria-hidden="true" tabindex="-1"></a>           <span class="at">min_n =</span> <span class="dv">2</span>, </span>
<span id="cb112-10"><a href="decision-trees.html#cb112-10" aria-hidden="true" tabindex="-1"></a>           <span class="at">tree_depth =</span> <span class="cn">NULL</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb112-11"><a href="decision-trees.html#cb112-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&#39;classification&#39;</span>) </span>
<span id="cb112-12"><a href="decision-trees.html#cb112-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb112-13"><a href="decision-trees.html#cb112-13" aria-hidden="true" tabindex="-1"></a>data_rec <span class="ot">&lt;-</span> <span class="fu">recipe</span>(class <span class="sc">~</span> ., <span class="at">data =</span> land)</span>
<span id="cb112-14"><a href="decision-trees.html#cb112-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb112-15"><a href="decision-trees.html#cb112-15" aria-hidden="true" tabindex="-1"></a>data_wf_tune <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">%&gt;%</span></span>
<span id="cb112-16"><a href="decision-trees.html#cb112-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_model</span>(ct_spec_tune) <span class="sc">%&gt;%</span></span>
<span id="cb112-17"><a href="decision-trees.html#cb112-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_recipe</span>(data_rec)</span>
<span id="cb112-18"><a href="decision-trees.html#cb112-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb112-19"><a href="decision-trees.html#cb112-19" aria-hidden="true" tabindex="-1"></a>param_grid <span class="ot">&lt;-</span> <span class="fu">grid_regular</span>(<span class="fu">cost_complexity</span>(<span class="at">range =</span> <span class="fu">c</span>(____, ____)), <span class="at">levels =</span> ____) </span>
<span id="cb112-20"><a href="decision-trees.html#cb112-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb112-21"><a href="decision-trees.html#cb112-21" aria-hidden="true" tabindex="-1"></a>tune_res <span class="ot">&lt;-</span> <span class="fu">tune_grid</span>(</span>
<span id="cb112-22"><a href="decision-trees.html#cb112-22" aria-hidden="true" tabindex="-1"></a>  data_wf_tune, </span>
<span id="cb112-23"><a href="decision-trees.html#cb112-23" aria-hidden="true" tabindex="-1"></a>  <span class="at">resamples =</span> data_fold, </span>
<span id="cb112-24"><a href="decision-trees.html#cb112-24" aria-hidden="true" tabindex="-1"></a>  <span class="at">grid =</span> param_grid, </span>
<span id="cb112-25"><a href="decision-trees.html#cb112-25" aria-hidden="true" tabindex="-1"></a>  <span class="at">metrics =</span> <span class="fu">metric_set</span>(accuracy) <span class="co">#change this for regression trees</span></span>
<span id="cb112-26"><a href="decision-trees.html#cb112-26" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<ol style="list-style-type: lower-alpha">
<li>Make a plot of test performance versus the <code>cost_complexity</code> tuning parameter. Does it look as you expected?</li>
</ol>
<div class="sourceCode" id="cb113"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb113-1"><a href="decision-trees.html#cb113-1" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(tune_res) <span class="sc">+</span> <span class="fu">theme_classic</span>()</span></code></pre></div>
<ol start="2" style="list-style-type: lower-alpha">
<li>Now choose the cost_complexity value that gives the simplest tree (high or low <code>cost_complexity</code>?) within 1 SE of the max accuracy. Pull out the CV accuracy for the chosen <code>cost_complexity</code>.</li>
</ol>
<div class="sourceCode" id="cb114"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb114-1"><a href="decision-trees.html#cb114-1" aria-hidden="true" tabindex="-1"></a>best_complexity <span class="ot">&lt;-</span> <span class="fu">select_by_one_std_err</span>(tune_res, <span class="at">metric =</span> <span class="st">&#39;accuracy&#39;</span>, <span class="fu">desc</span>(cost_complexity))</span>
<span id="cb114-2"><a href="decision-trees.html#cb114-2" aria-hidden="true" tabindex="-1"></a>data_wf_final <span class="ot">&lt;-</span> <span class="fu">finalize_workflow</span>(data_wf_tune, best_complexity)</span>
<span id="cb114-3"><a href="decision-trees.html#cb114-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb114-4"><a href="decision-trees.html#cb114-4" aria-hidden="true" tabindex="-1"></a>land_final_fit <span class="ot">&lt;-</span> <span class="fu">fit</span>(data_wf_final, <span class="at">data =</span> land)</span>
<span id="cb114-5"><a href="decision-trees.html#cb114-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb114-6"><a href="decision-trees.html#cb114-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb114-7"><a href="decision-trees.html#cb114-7" aria-hidden="true" tabindex="-1"></a>tune_res <span class="sc">%&gt;%</span> </span>
<span id="cb114-8"><a href="decision-trees.html#cb114-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">collect_metrics</span>() <span class="sc">%&gt;%</span></span>
<span id="cb114-9"><a href="decision-trees.html#cb114-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(cost_complexity <span class="sc">==</span> ________)</span></code></pre></div>
</div>
<div id="exercise-4-visualizing-trees" class="section level3 unnumbered hasAnchor">
<h3>Exercise 4: Visualizing trees<a href="decision-trees.html#exercise-4-visualizing-trees" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let’s visualize the difference between the trees learned under <code>cost_complexity</code> parameters. The code below fits a tree for a lower than optimal <code>cost_complexity</code> value (<code>tree_mod_lowcp</code>) and a higher than optimal <code>cost_complexity</code> (<code>tree_mod_highcp</code>). We then plot these trees (1st and 3rd) along with our best tree (2nd).</p>
<p>Look at page 3 of the <code>rpart.plot</code> <a href="http://www.milbo.org/doc/prp.pdf">package vignette</a> (an example-heavy manual) to understand what the plot components mean.</p>
<div class="sourceCode" id="cb115"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb115-1"><a href="decision-trees.html#cb115-1" aria-hidden="true" tabindex="-1"></a>tree_mod_lowcp <span class="ot">&lt;-</span> <span class="fu">fit</span>(</span>
<span id="cb115-2"><a href="decision-trees.html#cb115-2" aria-hidden="true" tabindex="-1"></a>    data_wf_tune <span class="sc">%&gt;%</span></span>
<span id="cb115-3"><a href="decision-trees.html#cb115-3" aria-hidden="true" tabindex="-1"></a>        <span class="fu">update_model</span>(ct_spec_tune <span class="sc">%&gt;%</span> <span class="fu">set_args</span>(<span class="at">cost_complexity =</span> .<span class="dv">00001</span>)),</span>
<span id="cb115-4"><a href="decision-trees.html#cb115-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> land</span>
<span id="cb115-5"><a href="decision-trees.html#cb115-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb115-6"><a href="decision-trees.html#cb115-6" aria-hidden="true" tabindex="-1"></a>tree_mod_highcp <span class="ot">&lt;-</span> <span class="fu">fit</span>(</span>
<span id="cb115-7"><a href="decision-trees.html#cb115-7" aria-hidden="true" tabindex="-1"></a>    data_wf_tune <span class="sc">%&gt;%</span></span>
<span id="cb115-8"><a href="decision-trees.html#cb115-8" aria-hidden="true" tabindex="-1"></a>        <span class="fu">update_model</span>(ct_spec_tune <span class="sc">%&gt;%</span> <span class="fu">set_args</span>(<span class="at">cost_complexity =</span> .<span class="dv">1</span>)),</span>
<span id="cb115-9"><a href="decision-trees.html#cb115-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> land</span>
<span id="cb115-10"><a href="decision-trees.html#cb115-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb115-11"><a href="decision-trees.html#cb115-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb115-12"><a href="decision-trees.html#cb115-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot all 3 trees in a row</span></span>
<span id="cb115-13"><a href="decision-trees.html#cb115-13" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">3</span>))</span>
<span id="cb115-14"><a href="decision-trees.html#cb115-14" aria-hidden="true" tabindex="-1"></a>tree_mod_lowcp <span class="sc">%&gt;%</span> <span class="fu">extract_fit_engine</span>() <span class="sc">%&gt;%</span> <span class="fu">rpart.plot</span>()</span>
<span id="cb115-15"><a href="decision-trees.html#cb115-15" aria-hidden="true" tabindex="-1"></a>land_final_fit <span class="sc">%&gt;%</span> <span class="fu">extract_fit_engine</span>() <span class="sc">%&gt;%</span> <span class="fu">rpart.plot</span>()</span>
<span id="cb115-16"><a href="decision-trees.html#cb115-16" aria-hidden="true" tabindex="-1"></a>tree_mod_highcp <span class="sc">%&gt;%</span> <span class="fu">extract_fit_engine</span>() <span class="sc">%&gt;%</span> <span class="fu">rpart.plot</span>()</span></code></pre></div>
<ul>
<li><p>Verify for a couple of splits the idea of increasing node purity/homogeneity in tree-building. (How is this idea reflected in the numbers in the plot output?)</p></li>
<li><p>Tuning classification trees (like with the <code>cost_complexity</code> parameter) is also referred to as <strong>“pruning”</strong>. Why does this make sense? NOTE: If “pruning” is a new word to you, first Google it.</p></li>
</ul>
</div>
</div>
<div id="exercises-part-2" class="section level2 unnumbered hasAnchor">
<h2>Exercises Part 2<a href="decision-trees.html#exercises-part-2" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="exercise-5-predictions-from-trees" class="section level3 unnumbered hasAnchor">
<h3>Exercise 5: Predictions from Trees<a href="decision-trees.html#exercise-5-predictions-from-trees" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ol style="list-style-type: lower-alpha">
<li>Looking at the plot of the best fitted tree, manually make a soft (probability) and hard (class) prediction for the case shown below.</li>
</ol>
<div class="sourceCode" id="cb116"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb116-1"><a href="decision-trees.html#cb116-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Pick out training case 2 to make a prediction</span></span>
<span id="cb116-2"><a href="decision-trees.html#cb116-2" aria-hidden="true" tabindex="-1"></a>test_case <span class="ot">&lt;-</span> land[<span class="dv">2</span>,]</span>
<span id="cb116-3"><a href="decision-trees.html#cb116-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Show only the needed predictors</span></span>
<span id="cb116-4"><a href="decision-trees.html#cb116-4" aria-hidden="true" tabindex="-1"></a>test_case <span class="sc">%&gt;%</span> <span class="fu">select</span>(NDVI, Bright_100, SD_NIR, GLCM2_100)</span>
<span id="cb116-5"><a href="decision-trees.html#cb116-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb116-6"><a href="decision-trees.html#cb116-6" aria-hidden="true" tabindex="-1"></a>land_final_fit <span class="sc">%&gt;%</span> <span class="fu">extract_fit_engine</span>() <span class="sc">%&gt;%</span> <span class="fu">rpart.plot</span>()</span></code></pre></div>
<ol start="2" style="list-style-type: lower-alpha">
<li>Verify your predictions with the <code>predict()</code> function. (Note: we introduced this code in Logistic Regression, but this type of code applies to any classification model fit in <code>tidymodels</code>).</li>
</ol>
<div class="sourceCode" id="cb117"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb117-1"><a href="decision-trees.html#cb117-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Soft (probability) prediction</span></span>
<span id="cb117-2"><a href="decision-trees.html#cb117-2" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(land_final_fit, <span class="at">new_data =</span> test_case, <span class="at">type =</span> <span class="st">&quot;prob&quot;</span>)</span>
<span id="cb117-3"><a href="decision-trees.html#cb117-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb117-4"><a href="decision-trees.html#cb117-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Hard (class) prediction</span></span>
<span id="cb117-5"><a href="decision-trees.html#cb117-5" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(land_final_fit, <span class="at">new_data =</span> test_case, <span class="at">type =</span> <span class="st">&quot;class&quot;</span>)</span></code></pre></div>
</div>
<div id="exercise-6-variable-importance-in-trees" class="section level3 unnumbered hasAnchor">
<h3>Exercise 6: Variable importance in trees<a href="decision-trees.html#exercise-6-variable-importance-in-trees" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We can obtain numerical variable importance measures from trees. These measure, roughly, “the total decrease in node impurities from splitting on the variable” (even if the variable isn’t ultimately used in the split).</p>
<p>What are the 3 most important predictors by this measure? Does this agree with you might have expected based on the plot of the best fitted tree? What might greedy behavior have to do with this?</p>
<div class="sourceCode" id="cb118"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb118-1"><a href="decision-trees.html#cb118-1" aria-hidden="true" tabindex="-1"></a>land_final_fit <span class="sc">%&gt;%</span></span>
<span id="cb118-2"><a href="decision-trees.html#cb118-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">extract_fit_engine</span>() <span class="sc">%&gt;%</span></span>
<span id="cb118-3"><a href="decision-trees.html#cb118-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pluck</span>(<span class="st">&#39;variable.importance&#39;</span>)</span></code></pre></div>
</div>
<div id="exercise-7-regression-trees" class="section level3 unnumbered hasAnchor">
<h3>Exercise 7: REGRESSION trees?!<a href="decision-trees.html#exercise-7-regression-trees" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Trees can also be used for regression! Let’s work through a step of building a regression tree by hand.</p>
<p>For the two possible splits below, determine the better split for the tree by computing the sum of squared residuals as the measure of node impurity. (The numbers following <code>Yes:</code> and <code>No:</code> indicate the outcome value of the cases in the left (Yes) and right (No) regions.)</p>
<div class="sourceCode" id="cb119"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb119-1"><a href="decision-trees.html#cb119-1" aria-hidden="true" tabindex="-1"></a>Split <span class="dv">1</span><span class="sc">:</span> x1 <span class="sc">&lt;</span> <span class="dv">3</span></span>
<span id="cb119-2"><a href="decision-trees.html#cb119-2" aria-hidden="true" tabindex="-1"></a>    <span class="sc">-</span> Yes<span class="sc">:</span> <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">4</span></span>
<span id="cb119-3"><a href="decision-trees.html#cb119-3" aria-hidden="true" tabindex="-1"></a>    <span class="sc">-</span> No<span class="sc">:</span> <span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">4</span></span>
<span id="cb119-4"><a href="decision-trees.html#cb119-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb119-5"><a href="decision-trees.html#cb119-5" aria-hidden="true" tabindex="-1"></a>Split <span class="dv">2</span><span class="sc">:</span> x1 <span class="sc">&lt;</span> <span class="dv">4</span></span>
<span id="cb119-6"><a href="decision-trees.html#cb119-6" aria-hidden="true" tabindex="-1"></a>    <span class="sc">-</span> Yes<span class="sc">:</span> <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">2</span></span>
<span id="cb119-7"><a href="decision-trees.html#cb119-7" aria-hidden="true" tabindex="-1"></a>    <span class="sc">-</span> No<span class="sc">:</span> <span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">4</span></span></code></pre></div>
<p>In case you want to explore building regression trees in R, try out the following exercises using the College data from the <code>ISLR</code> package. Our goal was to predict graduation rate (<code>Grad.Rate</code>) as a function of other predictors. You can look at the data codebook with <code>?College</code> in the Console.</p>
<div class="sourceCode" id="cb120"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb120-1"><a href="decision-trees.html#cb120-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ISLR)</span>
<span id="cb120-2"><a href="decision-trees.html#cb120-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb120-3"><a href="decision-trees.html#cb120-3" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(College)</span>
<span id="cb120-4"><a href="decision-trees.html#cb120-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb120-5"><a href="decision-trees.html#cb120-5" aria-hidden="true" tabindex="-1"></a><span class="co"># A little data cleaning</span></span>
<span id="cb120-6"><a href="decision-trees.html#cb120-6" aria-hidden="true" tabindex="-1"></a>college_clean <span class="ot">&lt;-</span> College <span class="sc">%&gt;%</span> </span>
<span id="cb120-7"><a href="decision-trees.html#cb120-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">school =</span> <span class="fu">rownames</span>(College)) <span class="sc">%&gt;%</span> </span>
<span id="cb120-8"><a href="decision-trees.html#cb120-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">filter</span>(Grad.Rate <span class="sc">&lt;=</span> <span class="dv">100</span>) <span class="co"># Remove one school with grad rate of 118%</span></span>
<span id="cb120-9"><a href="decision-trees.html#cb120-9" aria-hidden="true" tabindex="-1"></a><span class="fu">rownames</span>(college_clean) <span class="ot">&lt;-</span> <span class="cn">NULL</span> <span class="co"># Remove school names as row names</span></span></code></pre></div>
<ol style="list-style-type: lower-alpha">
<li>Adapt our general decision tree code for the regression setting by adapting the metric used to pick the final model. (Note how other parts stay the same!)</li>
</ol>
<p>Plot test performance as a function of <code>cost_complexity</code>, and comment on the shape of the plot.</p>
<p>Plot the “best” tree. (See page 3 of the <code>rpart.plot</code> package vignette for a refresher on what the plot shows.) Do the sequence of splits and outcomes in the leaf nodes make sense?</p>
<p>Look at the variable importance metrics from the best tree. Do the most important variables align with your intuition?</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="lasso-logistic-regression.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="bagging-and-random-forests.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
